<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> PUBLICATIONS | Slim Essid's research page </title> <meta name="author" content="Slim Essid"> <meta name="description" content="Slim Essid's research activities "> <meta name="keywords" content="AI, artificial intelligence, machine learning, deep learning, signal processing, audio, multimodal data, multimodal machine preception, multiview learning, representation learning, self supervised learning, machine listening, speech processing, source separation, DCASE"> <link rel="stylesheet" href="/research/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/research/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/research/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%92%A1&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/research/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://slimessid.github.io/research/publications/"> <link defer rel="stylesheet" href="/research/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/research/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/research//"> <span style="font-size: 1.1em">Slim Essid's research page </span> </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/research/">ABOUT </a> </li> <li class="nav-item active"> <a class="nav-link" href="/research/publications/">PUBLICATIONS <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/research/people/">PEOPLE </a> </li> <li class="nav-item "> <a class="nav-link" href="/research/projects/">PROJECTS </a> </li> <li class="nav-item "> <a class="nav-link" href="/research/teaching/">TEACHING </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">PUBLICATIONS</h1> <p class="post-description"></p> </header> <article> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/research/assets/img/publication_preview/benigmim_cvpr-24-480.webp 480w,/research/assets/img/publication_preview/benigmim_cvpr-24-800.webp 800w,/research/assets/img/publication_preview/benigmim_cvpr-24-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/research/assets/img/publication_preview/benigmim_cvpr-24.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="benigmim_cvpr-24.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="benigmim2023collaborating" class="col-sm-8"> <div class="title">COLLABORATING FOUNDATION MODELS FOR DOMAIN GENERALIZED SEMANTIC SEGMENTATION</div> <div class="author"> Y. Benigmim , S. Roy , <em>S. Essid</em>, V. Kalogeiton , and S. Lathuilière </div> <div class="periodical"> <em>In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2024)</em> , 2024 </div> <div class="periodical"> Accepted </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2312.09788.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p> Domain Generalized Semantic Segmentation (DGSS) deals with training a model on a labeled source domain with the aim of generalizing to unseen domains during inference. Existing DGSS methods typically effectuate robust features by means of Domain Randomization (DR). Such an approach is often limited as it can only account for style diversification and not content. In this work, we take an orthogonal approach to DGSS and propose to use an assembly of CoLlaborative FOUndation models for Domain Generalized Semantic Segmentation (CLOUDS). In detail, CLOUDS is a framework that integrates FMs of various kinds: (i) CLIP backbone for its robust feature representation, (ii) generative models to diversify the content, thereby covering various modes of the possible target distribution, and (iii) Segment Anything Model (SAM) for iteratively refining the predictions of the segmentation model. Extensive experiments show that our CLOUDS excels in adapting from synthetic to real DGSS benchmarks and under varying weather conditions, notably outperforming prior methods by 5.6% and 6.7% on averaged miou, respectively. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">benigmim2023collaborating</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Collaborating Foundation models for Domain Generalized Semantic Segmentation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Benigmim, Yasser and Roy, Subhankar and Essid, Slim and Kalogeiton, Vicky and Lathuilière, Stéphane}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2024)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2312.09788}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.CV}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Accepted}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/research/assets/img/publication_preview/buisson_taslp-24-480.webp 480w,/research/assets/img/publication_preview/buisson_taslp-24-800.webp 800w,/research/assets/img/publication_preview/buisson_taslp-24-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/research/assets/img/publication_preview/buisson_taslp-24.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="buisson_taslp-24.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="buisson:hal-04485065" class="col-sm-8"> <div class="title">SELF-SUPERVISED LEARNING OF MULTI-LEVEL AUDIO REPRESENTATIONS FOR MUSIC SEGMENTATION</div> <div class="author"> M. Buisson , B. Mcfee , <em>S. Essid</em>, and H. Crayencour </div> <div class="periodical"> <em>IEEE/ACM Transactions on Audio, Speech and Language Processing</em>, Mar 2024 </div> <div class="periodical"> Accepted </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://hal.science/hal-04485065/file/Buisson.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p> The task of music structure analysis refers to automatically identifying the location and the nature of musical sections within a song. In the supervised scenario, structural annotations generally result from exhaustive data collection processes, which represents one of the main challenges of this task. Moreover, both the subjectivity of music structure and the hierarchical characteristics it exhibits make the obtained structural annotations not fully reliable, in the sense that they do not convey a "universal ground-truth" unlike other tasks in music information retrieval. On the other hand, the quickly growing quantity of available music data has enabled weakly supervised and self-supervised approaches to achieve impressive results on a wide range of music-related problems. In this work, a self-supervised learning method is proposed to learn robust multi-level music representations prior to structural segmentation using contrastive learning. To this end, sets of frames sampled at different levels of detail are used to train a deep neural network in a disentangled manner. The proposed method is evaluated on both flat and multi-level segmentation. We show that each distinct sub-region of the output embeddings can efficiently account for structural similarity at their own targeted level of detail, which ultimately improves performance of downstream flat and multi-level segmentation. Finally, complementary experiments are carried out to study how the obtained representations can be further adapted to specific datasets using a supervised fine-tuning objective in order to facilitate structure retrieval in domains where human annotations remain scarce. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">buisson:hal-04485065</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Self-Supervised Learning of Multi-level Audio Representations for Music Segmentation}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Buisson, Morgan and Mcfee, Brian and Essid, Slim and Crayencour, Helene-Camille}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE/ACM Transactions on Audio, Speech and Language Processing}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://hal.science/hal-04485065}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Accepted}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Music structure analysis ; structural segmentation ; representation learning}</span><span class="p">,</span>
  <span class="na">hal_version</span> <span class="p">=</span> <span class="s">{v1}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="quelennec:hal-04360221" class="col-sm-8"> <div class="title">ON THE CHOICE OF THE OPTIMAL TEMPORAL SUPPORT FOR AUDIO CLASSIFICATION WITH PRE-TRAINED EMBEDDINGS</div> <div class="author"> A. Quelennec , M. Olvera , G. Peeters , and <em>S. Essid</em> </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2024)</em> , Apr 2024 </div> <div class="periodical"> Accepted </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://hal.science/hal-04360221/file/Pre_print_ICASSP_Paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p> Current state-of-the-art audio analysis systems rely on pre-trained embedding models, often used off-the-shelf as (frozen) feature extractors. Choosing the best one for a set of tasks is the subject of many recent publications. However, one aspect often overlooked in these works is the influence of the duration of audio input considered to extract an embedding, which we refer to as Temporal Support (TS). In this work, we study the influence of the TS for well-established or emerging pre-trained embeddings, chosen to represent different types of architectures and learning paradigms. We conduct this evaluation using both musical instrument and environmental sound datasets, namely OpenMIC, TAU Urban Acoustic Scenes 2020 Mobile, and ESC-50. We especially highlight that Audio Spectrogram Transformer-based systems (PaSST and BEATs) remain effective with smaller TS, which therefore allows for a drastic reduction in memory and computational cost. Moreover, we show that by choosing the optimal TS we reach competitive results across all tasks. In particular, we improve the state-of-the-art results on OpenMIC, using BEATs and PaSST without any fine-tuning. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">quelennec:hal-04360221</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{On the Choice of the Optimal Temporal Support for Audio Classification with Pre-trained Embeddings}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Quelennec, Aurian and Olvera, Michel and Peeters, Geoffroy and Essid, Slim}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://hal.science/hal-04360221}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{{IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2024)}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Accepted}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{audio embeddings ; acoustic scene classification ; instrument recognition ; temporal support ; transformers ; Representation Model}</span><span class="p">,</span>
  <span class="na">hal_id</span> <span class="p">=</span> <span class="s">{hal-04360221}</span><span class="p">,</span>
  <span class="na">hal_version</span> <span class="p">=</span> <span class="s">{v1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="gruttadauria:hal-04419041" class="col-sm-8"> <div class="title">ONLINE SPEAKER DIARIZATION OF MEETINGS GUIDED BY SPEECH SEPARATION</div> <div class="author"> E. Gruttadauria , M. Fontaine , and <em>S. Essid</em> </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2024)</em> , Apr 2024 </div> <div class="periodical"> Accepted </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://hal.science/hal-04419041/file/ICASSP_2024_ELIO_GRUTTADAURIA-final.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p> Overlapped speech is notoriously problematic for speaker diarization systems. Consequently, the use of speech separation has recently been proposed to improve their performance. Although promising, speech separation models struggle with realistic data because they are trained on simulated mixtures with a fixed number of speakers. In this work, we introduce a new speech separation-guided diarization scheme suitable for the online speaker diarization of long meeting recordings with a variable number of speakers, as present in the AMI corpus. We envisage ConvTasNet and DPRNN as alternatives for the separation networks, with two or three output sources. To obtain the speaker diarization result, voice activity detection is applied on each estimated source. The final model is fine-tuned end-to-end, after first adapting the separation to real data using AMI. The system operates on short segments, and inference is performed by stitching the local predictions using speaker embeddings and incremental clustering. The results show that our system improves the state-of-the-art on the AMI headset mix, using no oracle information and under full evaluation (no collar and including overlapped speech). Finally, we show the strength of our system particularly on overlapped speech sections. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">gruttadauria:hal-04419041</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Online Speaker Diarization of Meetings Guided by Speech Separation}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Gruttadauria, Elio and Fontaine, Mathieu and Essid, Slim}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://hal.science/hal-04419041}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Accepted}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{{IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2024)}}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Seoul (Korea), South Korea}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Speaker Diarization ; Source separation ; Online inference ; Overlapped speech ; AMI dataset ; Speaker embedding}</span><span class="p">,</span>
  <span class="na">hal_id</span> <span class="p">=</span> <span class="s">{hal-04419041}</span><span class="p">,</span>
  <span class="na">hal_version</span> <span class="p">=</span> <span class="s">{v1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="buisson:ismir23" class="col-sm-8"> <div class="title">A REPETITION-BASED TRIPLET MINING APPROACH FOR MUSIC SEGMENTATION</div> <div class="author"> M. Buisson , B. McFee , <em>S. Essid</em>, and H. Crayencour </div> <div class="periodical"> <em>In International Society for Music Information Retrieval (ISMIR)</em> , Nov 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://hal.science/hal-04202766/file/A%20Repetition-Based%20Triplet%20Mining%20Approach%20for%20Music%20Segmentation.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p> Contrastive learning has recently appeared as a well-suited method to find representations of music audio signals that are suitable for structural segmentation. However, most existing unsupervised training strategies omit the notion of repetition and therefore fail at encompassing this essential aspect of music structure. This work introduces a triplet mining method which explicitly considers repeating sequences occurring inside a music track by leveraging common audio descriptors. We study its impact on the learned representations through downstream music segmentation. Because musical repetitions can be of different natures, we give further insight on the role of the audio descriptors employed at the triplet mining stage as well as the trade-off existing between the quality of the triplets mined and the quantity of unlabelled data used for training. We observe that our method requires less non-annotated data while remaining competitive against other unsupervised methods trained on a larger corpus. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">buisson:ismir23</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Repetition-based Triplet Mining Approach for Music Segmentation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Buisson, Morgan and McFee, Brian and Essid, Slim and Crayencour, Hélène C.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Society for Music Information Retrieval (ISMIR)}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Milano, Italy}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/research/assets/img/publication_preview/letzelter_neurips-23-480.webp 480w,/research/assets/img/publication_preview/letzelter_neurips-23-800.webp 800w,/research/assets/img/publication_preview/letzelter_neurips-23-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/research/assets/img/publication_preview/letzelter_neurips-23.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="letzelter_neurips-23.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="letzelter:hal-04216055" class="col-sm-8"> <div class="title">RESILIENT MULTIPLE CHOICE LEARNING: A LEARNED SCORING SCHEME WITH APPLICATION TO AUDIO SCENE ANALYSIS</div> <div class="author"> V. Letzelter , M. Fontaine , P. Perez , G. Richard , <em>S. Essid</em>, and M. Chen </div> <div class="periodical"> <em>In Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS 2023)</em> , Dec 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://hal.science/hal-04216055/file/neurips_2023.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p> We introduce Resilient Multiple Choice Learning (rMCL), an extension of the MCL approach for conditional distribution estimation in regression settings where multiple targets may be sampled for each training input. Multiple Choice Learning is a simple framework to tackle multimodal density estimation, using the Winner-Takes-All (WTA) loss for a set of hypotheses. In regression settings, the existing MCL variants focus on merging the hypotheses, thereby eventually sacrificing the diversity of the predictions. In contrast, our method relies on a novel learned scoring scheme underpinned by a mathematical framework based on Voronoi tessellations of the output space, from which we can derive a probabilistic interpretation. After empirically validating rMCL with experiments on synthetic data, we further assess its merits on the sound source localization problem, demonstrating its practical usefulness and the relevance of its interpretation. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">letzelter:hal-04216055</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Resilient Multiple Choice Learning: A learned scoring scheme with application to audio scene analysis}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Letzelter, Victor and Fontaine, Mathieu and Perez, Patrick and Richard, Gael and Essid, Slim and Chen, Mickael}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://hal.science/hal-04216055}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS 2023)}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New Orleans, United States}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">hal_id</span> <span class="p">=</span> <span class="s">{hal-04216055}</span><span class="p">,</span>
  <span class="na">hal_version</span> <span class="p">=</span> <span class="s">{v1}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="zaiem:interspeech23" class="col-sm-8"> <div class="title">SPEECH SELF-SUPERVISED REPRESENTATION BENCHMARKING: ARE WE DOING IT RIGHT?</div> <div class="author"> S. Zaiem , T. Parcollet , and <em>S. Essid</em> </div> <div class="periodical"> <em>In Interspeech</em> , Aug 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://hal.science/hal-04216175/file/zaiem23b_interspeech.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zaiem:interspeech23</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Speech Self-Supervised Representation Benchmarking: Are We Doing it Right?}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zaiem, Salah and Parcollet, Titouan and Essid, Slim}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Interspeech}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Dublin, Ireland}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="zaiem:interspeech23b" class="col-sm-8"> <div class="title">AUTOMATIC DATA AUGMENTATION FOR DOMAIN ADAPTED FINE-TUNING OF SELF-SUPERVISED SPEECH REPRESENTATIONS</div> <div class="author"> S. Zaiem , T. Parcollet , and <em>S. Essid</em> </div> <div class="periodical"> <em>In Interspeech</em> , Aug 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://hal.science/hal-04216177/file/zaiem23_interspeech.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p> Self-Supervised Learning (SSL) has allowed leveraging large amounts of unlabeled speech data to improve the performance of speech recognition models even with small annotated datasets. Despite this, speech SSL representations may fail while facing an acoustic mismatch between the pretraining and target datasets. To address this issue, we propose a novel supervised domain adaptation method, designed for cases exhibiting such a mismatch in acoustic domains. It consists in applying properly calibrated data augmentations on a large clean dataset, bringing it closer to the target domain, and using it as part of an initial fine-tuning stage. Augmentations are automatically selected through the minimization of a conditional-dependence estimator, based on the target dataset. The approach is validated during an oracle experiment with controlled distortions and on two amateur-collected low-resource domains, reaching better performances compared to the baselines in both cases. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zaiem:interspeech23b</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Automatic Data Augmentation for Domain Adapted Fine-Tuning of Self-Supervised Speech Representations}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zaiem, Salah and Parcollet, Titouan and Essid, Slim}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Interspeech}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Dublin, Ireland}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Benigmim_2023_CVPR" class="col-sm-8"> <div class="title">ONE-SHOT UNSUPERVISED DOMAIN ADAPTATION WITH PERSONALIZED DIFFUSION MODELS</div> <div class="author"> Y. Benigmim , S. Roy , <em>S. Essid</em>, V. Kalogeiton , and S. Lathuiliere </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</em> , Jun 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p> Adapting a segmentation model from a labeled source domain to a target domain, where a single unlabeled datum is available, is one the most challenging problems in domain adaptation and is otherwise known as one-shot unsupervised domain adaptation (OSUDA). Most of the prior works have addressed the problem by relying on style transfer techniques, where the source images are stylized to have the appearance of the target domain. Departing from the common notion of transferring only the target “texture” information, we leverage text-to-image diffusion models (e.g., Stable Diffusion) to generate a synthetic target dataset with photo-realistic images that not only faithfully depict the style of the target domain, but are also characterized by novel scenes in diverse contexts. The text interface in our method Data AugmenTation with diffUsion Models (DATUM) endows us with the possibility of guiding the generation of images towards desired semantic concepts while respecting the original spatial context of a single training image, which is not possible in existing OSUDA methods. Extensive experiments on standard benchmarks show that our DATUM surpasses the state-of-the-art OSUDA methods by up to +7.1%. The implementation is available at https://github.com/yasserben/DATUM </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Benigmim_2023_CVPR</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Benigmim, Yasser and Roy, Subhankar and Essid, Slim and Kalogeiton, Vicky and Lathuiliere, Stephane}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{One-Shot Unsupervised Domain Adaptation With Personalized Diffusion Models}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{698-708}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="10095833" class="col-sm-8"> <div class="title">COSMOPOLITE SOUND MONITORING (COSMO): A STUDY OF URBAN SOUND EVENT DETECTION SYSTEMS GENERALIZING TO MULTIPLE CITIES</div> <div class="author"> F. Angulo , <em>S. Essid</em>, G. Peeters , and C. Mietlicki </div> <div class="periodical"> <em>In ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> , Jun 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10095833</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Angulo, Florian and Essid, Slim and Peeters, Geoffroy and Mietlicki, Christophe}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Cosmopolite Sound Monitoring (CoSMo): A Study of Urban Sound Event Detection Systems Generalizing to Multiple Cities}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-5}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICASSP49357.2023.10095833}</span><span class="p">,</span>
  <span class="na">abstrat</span> <span class="p">=</span> <span class="s">{
      Measuring noise in cities and automatically identifying the corresponding sound sources are a crucial challenge for policymakers. Indeed, such information helps addressing noise pollution and improving the well-being of urban dwellers. In recent years, researchers have provided annotated datasets recorded in two major cities to foster the development of urban sound event detection (SED) systems. This paper presents an in-depth study of the behaviour of state-of-the-art SED systems well suited to our problem, combining three far-field real recordings datasets which can be used jointly during training. In our evaluation, we highlight the performance gaps existing between simple and hard recording examples based on the salience of sound events and the polyphony of the recordings. We provide new proximity annotations for this analysis. We evaluate the ability of urban SED systems to generalize across cities with varying degrees of training supervision. We show that such generalization is hindered mostly by the difficulties current urban SED systems have to detect sound events with low salience along with sound events in highly polyphonic soundscapes.}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="zaiem:hal-04076307" class="col-sm-8"> <div class="title">FINE-TUNING STRATEGIES FOR FASTER INFERENCE USING SPEECH SELF-SUPERVISED MODELS: A COMPARATIVE STUDY</div> <div class="author"> S. Zaiem , R. Algayres , T. Parcollet , <em>S. Essid</em>, and M. Ravanelli </div> <div class="periodical"> <em>In ICASSP 2023 - International Conference on Acoustics, Speech, and Signal Processing</em> , Jun 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://hal.science/hal-04076307/file/2303.06740.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p> Self-supervised learning (SSL) has allowed substantial progress in Automatic Speech Recognition (ASR) performance in low-resource settings. In this context, it has been demonstrated that larger selfsupervised feature extractors are crucial for achieving lower downstream ASR error rates. Thus, better performance might be sanctioned with longer inferences. This article explores different approaches that may be deployed during the fine-tuning to reduce the computations needed in the SSL encoder, leading to faster inferences. We adapt a number of existing techniques to common ASR settings and benchmark them, displaying performance drops and gains in inference times. Interestingly, we found that given enough downstream data, a simple downsampling of the input sequences outperforms the other methods with both low performance drops and high computational savings, reducing computations by 61.3% with an WER increase of only 0.81. Finally, we analyze the robustness of the comparison to changes in dataset conditions, revealing sensitivity to dataset size. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zaiem:hal-04076307</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fine-tuning strategies for faster inference using speech self-supervised models: a comparative study}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zaiem, Salah and Algayres, Robin and Parcollet, Titouan and Essid, Slim and Ravanelli, Mirco}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://hal.science/hal-04076307}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICASSP 2023 - International Conference on Acoustics, Speech, and Signal Processing}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Rhodes, Greece}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Speech recognition ; Self-supervised learning}</span><span class="p">,</span>
  <span class="na">hal_id</span> <span class="p">=</span> <span class="s">{hal-04076307}</span><span class="p">,</span>
  <span class="na">hal_version</span> <span class="p">=</span> <span class="s">{v1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="perera:hal-03782827" class="col-sm-8"> <div class="title">LATENT AND ADVERSARIAL DATA AUGMENTATION FOR SOUND EVENT DETECTION AND CLASSIFICATION</div> <div class="author"> D. Perera , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>In International workshop on Detection and Classiffication of Acoustic Scenes and Events (DCASE)</em> , Nov 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://hal.science/hal-03782827/file/dcase.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p> Invariance-based learning is a promising approach in deep learning. Among other benefits, it can mitigate the lack of diversity of available datasets and increase the interpretability of trained models. To this end, practitioners often use a consistency cost penalizing the sensitivity of a model to a set of carefully selected data augmentations. However, there is no consensus about how these augmentations should be selected. In this paper, we study the behavior of several augmentation strategies. We consider the task of sound event detection and classification for our experiments. In particular, we show that transformations operating on the internal layers of a deep neural network are beneficial for this task. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">perera:hal-03782827</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Latent and Adversarial Data Augmentation for Sound Event Detection and Classification}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Perera, David and Essid, Slim and Richard, Ga{\"e}l}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://hal.science/hal-03782827}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{{International workshop on Detection and Classiffication of Acoustic Scenes and Events (DCASE)}}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Nancy, France}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{sound event detection ; data augmentation ; adversarial learning}</span><span class="p">,</span>
  <span class="na">hal_id</span> <span class="p">=</span> <span class="s">{hal-03782827}</span><span class="p">,</span>
  <span class="na">hal_version</span> <span class="p">=</span> <span class="s">{v1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="perera:hal-03759651" class="col-sm-8"> <div class="title">IMPACT DE PERTURBATIONS INTERNES SUR L ENTRAINEMENT DE RESEAUX PROFONDS POUR LA DETECTION D EVENEMENTS SONORES</div> <div class="author"> D. Perera , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>In Colloque Francophone de Traitement du Signal et des Images (GRETSI)</em> , Sep 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://hal.telecom-paris.fr/hal-03759651/file/perera927.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">perera:hal-03759651</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Impact de perturbations internes sur l entrainement de reseaux profonds pour la detection d evenements sonores}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Perera, David and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://hal.telecom-paris.fr/hal-03759651}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Colloque Francophone de Traitement du Signal et des Images (GRETSI)}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Nancy, France}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">hal_id</span> <span class="p">=</span> <span class="s">{hal-03759651}</span><span class="p">,</span>
  <span class="na">hal_version</span> <span class="p">=</span> <span class="s">{v1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/research/assets/img/publication_preview/zaiem_jstsp-23-480.webp 480w,/research/assets/img/publication_preview/zaiem_jstsp-23-800.webp 800w,/research/assets/img/publication_preview/zaiem_jstsp-23-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/research/assets/img/publication_preview/zaiem_jstsp-23.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="zaiem_jstsp-23.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="9846981" class="col-sm-8"> <div class="title">PRETEXT TASKS SELECTION FOR MULTITASK SELF-SUPERVISED AUDIO REPRESENTATION LEARNING</div> <div class="author"> S. Zaiem , T. Parcollet , <em>S. Essid</em>, and A. Heba </div> <div class="periodical"> <em>IEEE Journal of Selected Topics in Signal Processing</em>, Sep 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://hal.science/hal-03601330/file/2107.00594.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p> Through solving pretext tasks, self-supervised learning leverages unlabeled data to extract useful latent representations replacing traditional input features in the downstream task. In audio/speech signal processing, a wide range of features where engineered through decades of research efforts. As it turns out, learning to predict such features (a.k.a pseudo-labels) has proven to be a particularly relevant pretext task, leading to useful self-supervised representations which prove to be effective for downstream tasks. However, methods and common practices for combining such pretext tasks for better performance on the downstream task have not been explored and understood properly. In fact, the process relies almost exclusively on a computationally heavy experimental procedure, which becomes intractable with the increase of the number of pretext tasks. This paper introduces a method to select a group of pretext tasks among a set of candidates. The method we propose estimates calibrated weights for the partial losses corresponding to the considered pretext tasks during the self-supervised training process. The experiments conducted on automatic speech recognition, speaker and emotion recognition validate our approach, as the groups selected and weighted with our method perform better than classic baselines, thus facilitating the selection and combination of relevant pseudo-labels for self-supervised representation learning. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">9846981</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zaiem, Salah and Parcollet, Titouan and Essid, Slim and Heba, Abdelwahab}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Journal of Selected Topics in Signal Processing}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Pretext Tasks Selection for Multitask Self-Supervised Audio Representation Learning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{16}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1439-1453}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/JSTSP.2022.3195430}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="zaiem22_interspeech" class="col-sm-8"> <div class="title">AUTOMATIC DATA AUGMENTATION SELECTION AND PARAMETRIZATION IN CONTRASTIVE SELF-SUPERVISED SPEECH REPRESENTATION LEARNING</div> <div class="author"> S. Zaiem , T. Parcollet , and <em>S. Essid</em> </div> <div class="periodical"> <em>In Proc. Interspeech 2022</em> , Sep 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://hal.science/hal-03817736/file/IS2022%20%2814%29.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zaiem22_interspeech</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zaiem, Salah and Parcollet, Titouan and Essid, Slim}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Automatic Data Augmentation Selection and Parametrization in Contrastive Self-Supervised Speech Representation Learning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proc. Interspeech 2022}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{669--673}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.21437/Interspeech.2022-10191}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="buisson:hal-03780032" class="col-sm-8"> <div class="title">LEARNING MULTI-LEVEL REPRESENTATIONS FOR HIERARCHICAL MUSIC STRUCTURE ANALYSIS</div> <div class="author"> M. Buisson , B. McFee , <em>S. Essid</em>, and H. Crayencour </div> <div class="periodical"> <em>In International Society for Music Information Retrieval (ISMIR)</em> , Dec 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://hal.science/hal-03780032/file/Morgan_Buisson_ismir.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p> Recent work in music structure analysis has shown the potential of deep features to highlight the underlying structure of music audio signals. Despite promising results achieved by such representations, dealing with the inherent hierarchical aspect of music structure remains a challenging problem. Because different levels of segmentation can be considered as equally valid, specifically designed representations should be optimized to improve hierarchical structure analysis. In this work, unsupervised learning of such representations using a contrastive approach operating at different timescales is explored. The proposed system is evaluated on flat and multi-level music segmentation. By leveraging both time and the hierarchical organization of music structure, we show that the obtained deep embeddings can encode meaningful patterns and improve segmentation at various levels of granularity. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">buisson:hal-03780032</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Bengaluru, India}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Buisson, Morgan and McFee, Brian and Essid, Slim and Crayencour, Hélène C.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Society for Music Information Retrieval (ISMIR)}</span><span class="p">,</span>
  <span class="na">hal_id</span> <span class="p">=</span> <span class="s">{hal-03780032}</span><span class="p">,</span>
  <span class="na">hal_version</span> <span class="p">=</span> <span class="s">{v1}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning Multi-Level Representations for Hierarchical Music Structure Analysis}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://hal.archives-ouvertes.fr/hal-03780032}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="barriere:hal-04276012" class="col-sm-8"> <div class="title">OPINIONS IN INTERACTIONS : NEW ANNOTATIONS OF THE SEMAINE DATABASE</div> <div class="author"> V. Barrière , C. Clavel , and <em>S. Essid</em> </div> <div class="periodical"> <em>In LREC</em> , Jun 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://hal.science/hal-04276012/file/2022.lrec-1.762.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">barriere:hal-04276012</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Opinions in Interactions : New Annotations of the SEMAINE Database}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Barri{\`e}re, Valentin and Clavel, Chlo{\'e} and Essid, Slim}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://hal.science/hal-04276012}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{{LREC}}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Marseille, France}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Opinion Multimodal Machine Learning Interactions ; Opinion ; Multimodal Machine Learning ; Interactions}</span><span class="p">,</span>
  <span class="na">hal_id</span> <span class="p">=</span> <span class="s">{hal-04276012}</span><span class="p">,</span>
  <span class="na">hal_version</span> <span class="p">=</span> <span class="s">{v1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/research/assets/img/publication_preview/furnon_taslp-21-480.webp 480w,/research/assets/img/publication_preview/furnon_taslp-21-800.webp 800w,/research/assets/img/publication_preview/furnon_taslp-21-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/research/assets/img/publication_preview/furnon_taslp-21.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="furnon_taslp-21.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="furnon:hal-02985867" class="col-sm-8"> <div class="title">DNN-BASED MASK ESTIMATION FOR DISTRIBUTED SPEECH ENHANCEMENT IN SPATIALLY UNCONSTRAINED MICROPHONE ARRAYS</div> <div class="author"> N. Furnon , R. Serizel , <em>S. Essid</em>, and I. Illina </div> <div class="periodical"> <em>IEEE/ACM Transactions on Audio, Speech and Language Processing</em>, Jun 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://hal.archives-ouvertes.fr/hal-02985867v3/file/furnon.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p> Deep neural network (DNN)-based speech enhancement algorithms in microphone arrays have now proven to be efficient solutions to speech understanding and speech recognition in noisy environments. However, in the context of ad-hoc microphone arrays, many challenges remain and raise the need for distributed processing. In this paper, we propose to extend a previously introduced distributed DNN-based time-frequency mask estimation scheme that can efficiently use spatial information in form of so-called compressed signals which are pre-filtered target estimations. We study the performance of this algorithm named Tango under realistic acoustic conditions and investigate practical aspects of its optimal application. We show that the nodes in the microphone array cooperate by taking profit of their spatial coverage in the room. We also propose to use the compressed signals not only to convey the target estimation but also the noise estimation in order to exploit the acoustic diversity recorded throughout the microphone array. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">furnon:hal-02985867</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{DNN-based mask estimation for distributed speech enhancement in spatially unconstrained microphone arrays}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Furnon, Nicolas and Serizel, Romain and Essid, Slim and Illina, Irina}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://hal.archives-ouvertes.fr/hal-02985867}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE/ACM Transactions on Audio, Speech and Language Processing}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{29}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2310 - 2323}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TASLP.2021.3092838}</span><span class="p">,</span>
  <span class="na">hal_id</span> <span class="p">=</span> <span class="s">{hal-02985867}</span><span class="p">,</span>
  <span class="na">hal_version</span> <span class="p">=</span> <span class="s">{v3}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="cantisani:hal-03219350" class="col-sm-8"> <div class="title">USER-GUIDED ONE-SHOT DEEP MODEL ADAPTATION FOR MUSIC SOURCE SEPARATION</div> <div class="author"> g. Cantisani , A. Ozerov , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>In 2021 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)</em> , Oct 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://hal.telecom-paris.fr/hal-03219350v3/file/UGOSA_Hal.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">cantisani:hal-03219350</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{User-guided one-shot deep model adaptation for music source separation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cantisani, giorgia and Ozerov, Alexey and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://hal.telecom-paris.fr/hal-03219350}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2021 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New Paltz, USA}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Music Source Separation ; User-guided Source Separation ; One-shot Domain Adaptation}</span><span class="p">,</span>
  <span class="na">hal_id</span> <span class="p">=</span> <span class="s">{hal-03219350}</span><span class="p">,</span>
  <span class="na">hal_version</span> <span class="p">=</span> <span class="s">{v3}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="furnon:hal-03259801" class="col-sm-8"> <div class="title">ATTENTION-BASED DISTRIBUTED SPEECH ENHANCEMENT FOR UNCONSTRAINED MICROPHONE ARRAYS WITH VARYING NUMBER OF NODES</div> <div class="author"> N. Furnon , R. Serizel , <em>S. Essid</em>, and I. Illina </div> <div class="periodical"> <em>In European Signal Processing Conference (EUSIPCO)</em> , Aug 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://hal.archives-ouvertes.fr/hal-03259801/file/eusipco2021.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">furnon:hal-03259801</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Attention-based distributed speech enhancement for unconstrained microphone arrays with varying number of nodes}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Furnon, Nicolas and Serizel, Romain and Essid, Slim and Illina, Irina}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://hal.archives-ouvertes.fr/hal-03259801}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{European Signal Processing Conference (EUSIPCO)}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Dublin/ Virtual, Ireland}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Speech enhancement ; distributed processing ; attention mechanisms ; ad-hoc microphone arrays}</span><span class="p">,</span>
  <span class="na">hal_id</span> <span class="p">=</span> <span class="s">{hal-03259801}</span><span class="p">,</span>
  <span class="na">hal_version</span> <span class="p">=</span> <span class="s">{v1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="furnon:hal-02985794" class="col-sm-8"> <div class="title">DISTRIBUTED SPEECH SEPARATION IN SPATIALLY UNCONSTRAINED MICROPHONE ARRAYS</div> <div class="author"> N. Furnon , R. Serizel , I. Illina , and <em>S. Essid</em> </div> <div class="periodical"> <em>In ICASSP 2021 - 46th International Conference on Acoustics, Speech, and Signal Processing</em> , Jun 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://hal.archives-ouvertes.fr/hal-02985794v2/file/icassp2021.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">furnon:hal-02985794</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Distributed speech separation in spatially unconstrained microphone arrays}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Furnon, Nicolas and Serizel, Romain and Illina, Irina and Essid, Slim}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://hal.archives-ouvertes.fr/hal-02985794}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICASSP 2021 - 46th International Conference on Acoustics, Speech, and Signal Processing}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Toronto, Canada}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Speech separation ; Microphone arrays ; Distributed processing ; Speech separation}</span><span class="p">,</span>
  <span class="na">hal_id</span> <span class="p">=</span> <span class="s">{hal-02985794}</span><span class="p">,</span>
  <span class="na">hal_version</span> <span class="p">=</span> <span class="s">{v2}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="cantisani:hal-02978978" class="col-sm-8"> <div class="title">NEURO-STEERED MUSIC SOURCE SEPARATION WITH EEG-BASED AUDITORY ATTENTION DECODING AND CONTRASTIVE-NMF</div> <div class="author"> G. Cantisani , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>In ICASSP 2021 - 46th International Conference on Acoustics, Speech, and Signal Processing</em> , Jun 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://hal.telecom-paris.fr/hal-02978978v4/file/C-NMF-Hal.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p> We propose a novel informed music source separation paradigm, which can be referred to as neuro-steered music source separation. More precisely, the source separation process is guided by the user’s selective auditory attention decoded from his/her EEG response to the stimulus. This high-level prior information is used to select the desired instrument to isolate and to adapt the generic source separation model to the observed signal. To this aim, we leverage the fact that the attended instrument’s neural encoding is substantially stronger than the one of the unattended sources left in the mixture. This "contrast" is extracted using an attention decoder and used to inform a source separation model based on non-negative matrix fac-torization named Contrastive-NMF. The results are promising and show that the EEG information can automatically select the desired source to enhance and improve the separation quality. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">cantisani:hal-02978978</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{NEURO-STEERED MUSIC SOURCE SEPARATION WITH EEG-BASED AUDITORY ATTENTION DECODING AND CONTRASTIVE-NMF}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cantisani, Giorgia and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://hal.telecom-paris.fr/hal-02978978}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICASSP 2021 - 46th International Conference on Acoustics, Speech, and Signal Processing}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Toronto, Canada}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Index Terms-Audio source separation ; Auditory attention decoding ; Polyphonic music ; EEG ; Audio source separation}</span><span class="p">,</span>
  <span class="na">hal_id</span> <span class="p">=</span> <span class="s">{hal-02978978}</span><span class="p">,</span>
  <span class="na">hal_version</span> <span class="p">=</span> <span class="s">{v4}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="zaiem21_interspeech" class="col-sm-8"> <div class="title">CONDITIONAL INDEPENDENCE FOR PRETEXT TASK SELECTION IN SELF-SUPERVISED SPEECH REPRESENTATION LEARNING</div> <div class="author"> S. Zaiem , T. Parcollet , and <em>S. Essid</em> </div> <div class="periodical"> <em>In Interspeech</em> , Aug 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2021/zaiem21_interspeech.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zaiem21_interspeech</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zaiem, Salah and Parcollet, Titouan and Essid, Slim}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Conditional Independence for Pretext Task Selection in Self-Supervised Speech Representation Learning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Interspeech}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2851--2855}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.21437/Interspeech.2021-1027}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:patent20" class="col-sm-8"> <div class="title">METHOD AND SYSTEM FOR BROADCASTING A MULTICHANNEL AUDIO STREAM TO TERMINALS OF SPECTATORS ATTENDING A SPORTS EVENT</div> <div class="author"> R. Blouet , and <em>S. Essid</em> </div> <div class="periodical"> <em>Patent Application</em>, Sep 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/US20210014627A1.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">SE:patent20</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Blouet, Raphael and Essid, Slim}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Method and System for Broadcasting a Multichannel Audio Stream to Terminals of Spectators Attending a Sports Event}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Patent Application}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{US 2021/0014627 A1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="furnon:hal-02389159" class="col-sm-8"> <div class="title">DNN-BASED DISTRIBUTED MULTICHANNEL MASK ESTIMATION FOR SPEECH ENHANCEMENT IN MICROPHONE ARRAYS</div> <div class="author"> N. Furnon , R. Serizel , I. Illina , and <em>S. Essid</em> </div> <div class="periodical"> <em>In ICASSP 2020 - 45th International Conference on Acoustics, Speech, and Signal Processing</em> , May 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://hal.science/hal-02985867v3/file/furnon.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">furnon:hal-02389159</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{DNN-Based Distributed Multichannel Mask Estimation for Speech Enhancement in Microphone Arrays}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Furnon, Nicolas and Serizel, Romain and Illina, Irina and Essid, Slim}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://hal.archives-ouvertes.fr/hal-02389159}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICASSP 2020 - 45th International Conference on Acoustics, Speech, and Signal Processing}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Barcelona, Spain}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Index Terms-Speech enhancement ; dis- tributed processing ; microphone arrays ; Distributed processing ; Speech enhancement}</span><span class="p">,</span>
  <span class="na">hal_id</span> <span class="p">=</span> <span class="s">{hal-02389159}</span><span class="p">,</span>
  <span class="na">hal_version</span> <span class="p">=</span> <span class="s">{v3}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/research/assets/img/publication_preview/parekh_taslp-19-480.webp 480w,/research/assets/img/publication_preview/parekh_taslp-19-800.webp 800w,/research/assets/img/publication_preview/parekh_taslp-19-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/research/assets/img/publication_preview/parekh_taslp-19.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="parekh_taslp-19.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="8926380" class="col-sm-8"> <div class="title">WEAKLY SUPERVISED REPRESENTATION LEARNING FOR AUDIO-VISUAL SCENE ANALYSIS</div> <div class="author"> S. Parekh , <em>S. Essid</em>, A. Ozerov , N. Duong , P. Pérez , and G. Richard </div> <div class="periodical"> <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, May 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://telecom-paris.hal.science/hal-02399993/file/2019-IEEE_TASLP_Parekh.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p> Audiovisual (AV) representation learning is an important task from the perspective of designing machines with the ability to understand complex events. To this end, we propose a novel multimodal framework that instantiates multiple instance learning. Specifically, we develop methods that identify events and localize corresponding AV cues in unconstrained videos. Importantly, this is done using weak labels where only video-level event labels are known without any information about their location in time. We show that the learnt representations are useful for performing several tasks such as event/object classification, audio event detection, audio source separation and visual object localization. An important feature of our method is its capacity to learn from unsynchronized audiovisual events. We also demonstrate our framework’s ability to separate out the audio source of interest through a novel use of nonnegative matrix factorization. State-of-the-art classification results, with a F1-score of 65.0, are achieved on DCASE 2017 smart cars challenge data with promising generalization to diverse object types such as musical instruments. Visualizations of localized visual regions and audio segments substantiate our system’s efficacy, especially when dealing with noisy situations where modality-specific cues appear asynchronously. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">8926380</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Parekh, S. and Essid, Slim and Ozerov, A. and Duong, N. Q. K. and Pérez, P. and Richard, G.}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE/ACM Transactions on Audio, Speech, and Language Processing}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Weakly Supervised Representation Learning for Audio-Visual Scene Analysis}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{28}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{416-428}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="benyoussef:hal-02288044" class="col-sm-8"> <div class="title">ON-THE-FLY DETECTION OF USER ENGAGEMENT DECREASE IN SPONTANEOUS HUMAN-ROBOT INTERACTION</div> <div class="author"> A. Ben Youssef , G. Varni , <em>S. Essid</em>, and C. Clavel </div> <div class="periodical"> <em>International Journal of Social Robotics</em>, Jan 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">benyoussef:hal-02288044</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{On-the-fly Detection of User Engagement Decrease in Spontaneous Human-Robot Interaction}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ben Youssef, Atef and Varni, Giovanna and Essid, Slim and Clavel, Chloe}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://hal.telecom-paris.fr/hal-02288044}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{International Journal of Social Robotics}</span><span class="p">,</span>
  <span class="na">hal_local_reference</span> <span class="p">=</span> <span class="s">{ABY:IJSR-2019}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{User engagement decrease ; Socially assistive robot ; HRI in public space ; Real-time detection}</span><span class="p">,</span>
  <span class="na">hal_id</span> <span class="p">=</span> <span class="s">{hal-02288044}</span><span class="p">,</span>
  <span class="na">hal_version</span> <span class="p">=</span> <span class="s">{v1}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="DBLP:journals/corr/abs-1902-10102" class="col-sm-8"> <div class="title">A MULTIMODAL MOVIE REVIEW CORPUS FOR FINE-GRAINED OPINION MINING</div> <div class="author"> A. Garcia , <em>S. Essid</em>, F. DAlche-Buc , and C. Clavel </div> <div class="periodical"> Jan 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@techreport</span><span class="p">{</span><span class="nl">DBLP:journals/corr/abs-1902-10102</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Garcia, Alexandre and Essid, Slim and DAlche-Buc, Florence and Clavel, Chloe}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A multimodal movie review corpus for fine-grained opinion mining}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{abs/1902.10102}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://arxiv.org/abs/1902.10102}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{1902.10102}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Fri, 24 May 2019 10:20:38 +0200}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/bib/journals/corr/abs-1902-10102}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Garcia2019" class="col-sm-8"> <div class="title">FROM THE TOKEN TO THE REVIEW: A HIERARCHICAL MULTIMODAL APPROACH TO OPINION MINING</div> <div class="author"> A. Garcia , P. Colombo , F. DAlche-Buc , <em>S. Essid</em>, and C. Clavel </div> <div class="periodical"> <em>In 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing</em> , Nov 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Garcia2019</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Garcia, Alexandre and Colombo, Pierre and DAlche-Buc, Florence and Essid, Slim and Clavel, Chloe}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{From the Token to the Review: A Hierarchical Multimodal approach to Opinion Mining}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Hong Kong, China}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Cantisani2019b" class="col-sm-8"> <div class="title">MAD-EEG: AN EEG DATASET FOR DECODING AUDITORY ATTENTION TO A TARGET INSTRUMENT IN POLYPHONIC MUSIC</div> <div class="author"> G. Cantisani , G. Tregoat , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>In Speech, Music and Mind (SMM19), Satellite workshop of Interspeech 2019</em> , Nov 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Cantisani2019b</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cantisani, Giorgia and Tregoat, Gabriel and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Speech, Music and Mind (SMM19), Satellite workshop of Interspeech 2019}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{MAD-EEG: an EEG dataset for decoding auditory attention to a target	instrument in polyphonic music}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Vienna, Austria}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Parekh2019" class="col-sm-8"> <div class="title">IDENTIFY, LOCATE AND SEPARATE: AUDIO-VISUAL OBJECT EXTRACTION IN LARGE VIDEO COLLECTIONS USING WEAK SUPERVISION</div> <div class="author"> S. Parekh , A. Ozerov , <em>S. Essid</em>, N. Duong , P. Perez , and G. Richard </div> <div class="periodical"> <em>In 2019 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)</em> , Oct 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Parekh2019</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Parekh, Sanjeel and Ozerov, Alexey and Essid, Slim and Duong, Ngoc Q. K. and Perez, Patrick and Richard, Gael}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2019 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Identify, Locate and Separate: Audio-visual Object Extraction in Large Video Collections Using Weak Supervision}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New Paltz, USA}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Cantisani2019" class="col-sm-8"> <div class="title">EEG-BASED DECODING OF AUDITORY ATTENTION TO A TARGET INSTRUMENT IN POLYPHONIC MUSIC</div> <div class="author"> G. Cantisani , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>In 2019 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)</em> , Oct 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Cantisani2019</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cantisani, Giorgia and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2019 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{EEG-based Decoding of Auditory Attention to a Target Instrument in Polyphonic Music}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New Paltz, USA}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Maia2019" class="col-sm-8"> <div class="title">SAMBASET: A DATASET OF HISTORICAL SAMBA DE ENREDO RECORDINGS FOR COMPUTATIONAL MUSIC ANALYSIS</div> <div class="author"> L. Maia , M. Fuentes , L. Biscainho , M. Rocamora , and <em>S. Essid</em> </div> <div class="periodical"> <em>In The 20th International Society for Music Information Retrieval Conference</em> , Nov 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Maia2019</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Maia, Lucas S. and Fuentes, Magdalena and Biscainho, Luiz W. P. and Rocamora, Martin and Essid, Slim}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The 20th International Society for Music Information Retrieval Conference}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{SAMBASET: A Dataset of Historical Samba de Enredo Recordings for Computational Music Analysis}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Delft, The Netherlands}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Fuentes2019b" class="col-sm-8"> <div class="title">TRACKING BEATS AND MICROTIMING IN AFRO-LATIN AMERICAN MUSIC USING CONDITIONAL RANDOM FIELDS AND DEEP LEARNING</div> <div class="author"> M. Fuentes , L. Maia , M. Rocamora , L. Biscainho , H. Crayencour , <em>S. Essid</em>, and J. Bello </div> <div class="periodical"> <em>In The 20th International Society for Music Information Retrieval Conference</em> , Nov 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Fuentes2019b</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fuentes, Magdalena and Maia, Lucas S. and Rocamora, Martin and Biscainho, Luiz W. P. and Crayencour, Helene C. and Essid, Slim and Bello, Juan Pablo}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The 20th International Society for Music Information Retrieval Conference}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Tracking Beats And Microtiming In Afro-latin American
  	music Using Conditional Random Fields and Deep Learning}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Delft, The Netherlands}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Fuentes2019" class="col-sm-8"> <div class="title">A MUSIC STRUCTURE INFORMED DOWNBEAT TRACKING SYSTEM USING SKIP-CHAIN CONDITIONAL RANDOM FIELDS AND DEEP LEARNING</div> <div class="author"> M. Fuentes , B. McFee , H. Crayencour , <em>S. Essid</em>, and J. Bello </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech and Signal processing</em> , May 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Fuentes2019</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fuentes, Magdalena and McFee, Brian and Crayencour, Helene and Essid, Slim and Bello, Juan Pablo}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Acoustics, Speech and Signal processing}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Music Structure Informed Downbeat Tracking System Using Skip-Chain Conditional Random Fields and Deep Learning}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Brighton, UK}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Duan2019" class="col-sm-8"> <div class="title">AUDIOVISUAL ANALYSIS OF MUSIC PERFORMANCES: OVERVIEW OF AN EMERGING FIELD</div> <div class="author"> Z. Duan , S. Essid , C. Liem , G. Richard , and G. Sharma </div> <div class="periodical"> <em>IEEE Signal Processing Magazine</em>, Jan 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Duan2019</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Duan, Z. and Essid, S. and Liem, C. C. S. and Richard, G. and Sharma, G.}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Signal Processing Magazine}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Audiovisual Analysis of Music Performances: Overview of an Emerging Field}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{36}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{63-73}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{audio signal processing;music;audiovisual analysis;audio modality;music recordings;audio-only media;automated music analysis;audio signals;acoustic music rendering;Music;Visualization;Task analysis;Instruments;Multiple signal classification;Signal processing;Cameras;Acoustics}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/MSP.2018.2875511}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1053-5888}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="BenYoussef2019" class="col-sm-8"> <div class="title">EARLY DETECTION OF USER ENGAGEMENT BREAKDOWN IN SPONTANEOUS HUMAN-HUMANOID INTERACTION</div> <div class="author"> A. Ben Youssef , C. Clavel , and S. Essid </div> <div class="periodical"> <em>IEEE Transactions on Affective Computing</em>, Jan 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">BenYoussef2019</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ben Youssef, A and Clavel, C and Essid, S}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TAFFC.2019.2898399}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1949-3045}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Affective Computing}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Robots;Electric breakdown;Feature extraction;Predi}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Early Detection of User Engagement Breakdown in Spontaneous Human-Humanoid Interaction}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2018</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:patent18" class="col-sm-8"> <div class="title">PROCEDE ET SYSTEME DE DIFFUSION D UN FLUX AUDIO MULTICANAL A DES TERMINAUX DE SPECTATEURS ASSISTANT A UN EVENEMENT SPORTIF</div> <div class="author"> R. Blouet , and <em>S. Essid</em> </div> <div class="periodical"> <em>Patent Application</em>, Mar 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/FR3079706B1.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">SE:patent18</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Blouet, Raphael and Essid, Slim}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Procede et Systeme de Diffusion d un Flux Audio Multicanal a des terminaux de spectateurs assistant a un evenement sportif}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Patent Application}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1852774}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="lostanlen_vincent_2018_1344103" class="col-sm-8"> <div class="title">MEDLEY-SOLOS-DB: A CROSS-COLLECTION DATASET FOR MUSICAL INSTRUMENT RECOGNITION</div> <div class="author"> V. Lostanlen , C. Cella , R. Bittner , and <em>S. Essid</em> </div> <div class="periodical"> Sep 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">lostanlen_vincent_2018_1344103</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lostanlen, Vincent and Cella, Carmine-Emanuele and Bittner, Rachel and Essid, Slim}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Medley-solos-DB: a cross-collection dataset for
  	musical instrument recognition}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.5281/zenodo.1344103}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.5281/zenodo.1344103}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Hajlaoui2018" class="col-sm-8"> <div class="title">EEG-BASED INTER-SUBJECT CORRELATION SCHEMES IN A STIMULI-SHARED FRAMEWORK: INTERPLAY WITH VALENCE AND AROUSAL</div> <div class="author"> A. Hajlaoui , M. Chetouani , and <em>S. Essid</em> </div> <div class="periodical"> <em></em> Sep 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Hajlaoui2018</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">arxivid</span> <span class="p">=</span> <span class="s">{1809.08273}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hajlaoui, Ayoub and Chetouani, Mohamed and Essid, Slim}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{1809.08273}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{EEG-based Inter-Subject Correlation Schemes in a Stimuli-Shared Framework: Interplay with Valence and Arousal}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/1809.08273}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Fuentes2018" class="col-sm-8"> <div class="title">ANALYSIS OF COMMON DESIGN CHOICES IN DEEP LEARNING SYSTEMS FOR DOWNBEAT TRACKING</div> <div class="author"> M. Fuentes , B. McFee , H. Crayencour , <em>S. Essid</em>, and J. Bello </div> <div class="periodical"> <em>In Proceedings of the 19th International Society for Music Information Retrieval Conference</em> , Sep 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Fuentes2018</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Paris, France}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fuentes, Magdalena and McFee, Brian and Crayencour, Helene C and Essid, Slim and Bello, Juan Pablo}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 19th International Society for Music Information Retrieval Conference}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.5281/zenodo.1492355}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{106--112}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ISMIR}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Analysis of Common Design Choices in Deep Learning Systems for Downbeat Tracking}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.5281/zenodo.1492355}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Basaran2018" class="col-sm-8"> <div class="title">MAIN MELODY ESTIMATION WITH SOURCE-FILTER NMF AND CRNN</div> <div class="author"> D. Basaran , <em>S. Essid</em>, and G. Peeters </div> <div class="periodical"> <em>In Proceedings of the 19th International Society for Music Information Retrieval Conference</em> , Sep 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Basaran2018</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Paris, France}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Basaran, Dogac and Essid, Slim and Peeters, Geoffroy}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 19th International Society for Music Information Retrieval Conference}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.5281/zenodo.1492349}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{82--89}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ISMIR}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Main Melody Estimation with Source-Filter NMF and CRNN}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.5281/zenodo.1492349}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Hong2018" class="col-sm-8"> <div class="title">A ROBUST AUDIO CLASSIFICATION SYSTEM FOR DETECTING PULMONARY EDEMA</div> <div class="author"> K. Hong , S. Essid , W. Ser , and D. Foo </div> <div class="periodical"> <em>Biomedical Signal Processing and Control</em>, Sep 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>In this paper we present a robust audio classification system to efficiently detect pulmonary edema. The system uses a feature learning technique based on (NMF), then classified with logistic regression. A study was done to compare feature engineering approaches with feature selection techniques against NMF. Different NMF schemes were investigated and also compared with Principal Component Analysis. NMF scored 95% F1 score, which was superior to feature engineering techniques that had scores from 83% to 93%. Background noise collected from hospitals and speech from a speech corpus database was used to simulate noisy data. The system was then tested using noisy data. The best NMF scheme scored 74%, while other feature engineering techniques scored lower; from 66% to 71%. NMF was also used as a signal enhancement tool. It improved the F1 score to 77%. Lastly, only inhalations from breath sounds were considered and this further improved classification results to 86%. The proposed robust classification system using NMF thus proved to be an effective method for audio-based detection of pulmonary edema. If implemented in real-time, the proposed system can be used as a screening tool.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Hong2018</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hong, K. J. and Essid, S. and Ser, W. and Foo, D. C.G.}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.bspc.2018.07.004}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{17468108}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Biomedical Signal Processing and Control}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Biomedical signal processing,Feature learning,Non-negative matrix factorization,Pulmonary edema,Robust testing}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A robust audio classification system for detecting pulmonary edema}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Hajlaoui2019" class="col-sm-8"> <div class="title">MULTI-TASK FEATURE LEARNING FOR EEG-BASED EMOTION RECOGNITION USING GROUP NONNEGATIVE MATRIX FACTORIZATION</div> <div class="author"> A. Hajlaoui , M. Chetouani , and <em>S. Essid</em> </div> <div class="periodical"> <em>In The European Signal Processing Conference (EUSIPCO)</em> , Sep 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Hajlaoui2019</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Rome, Italy}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hajlaoui, Ayoub and Chetouani, Mohamed and Essid, Slim}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The European Signal Processing Conference (EUSIPCO)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Multi-task Feature Learning for EEG-based Emotion Recognition Using Group Nonnegative Matrix Factorization}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Garcia2018b" class="col-sm-8"> <div class="title">STRUCTURED OUTPUT LEARNING WITH ABSTENTION: APPLICATION TO ACCURATE OPINION PREDICTION</div> <div class="author"> A. Garcia , <em>S. Essid</em>, C. Clavel , and F. DAlche-Buc </div> <div class="periodical"> <em>In International Conference on Machine Learning (ICML)</em> , Jul 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Motivated by Supervised Opinion Analysis, we propose a novel framework devoted to Structured Output Learning with Abstention (SOLA). The structure prediction model is able to abstain from predicting some labels in the structured output at a cost chosen by the user in a flexible way. For that purpose, we decompose the problem into the learning of a pair of predictors, one devoted to structured abstention and the other, to structured output prediction. To compare fully labeled training data with predictions potentially containing abstentions, we define a wide class of asymmetric abstention-aware losses. Learning is achieved by surrogate regression in an appropriate feature space while prediction with abstention is performed by solving a new pre-image problem. Thus, SOLA extends recent ideas about Structured Output Prediction via surrogate problems and calibration theory and enjoys statistical guarantees on the resulting excess risk. Instantiated on a hierarchical abstention-aware loss, SOLA is shown to be relevant for fine-grained opinion mining and gives state-of-the-art results on this task. Moreover, the abstention-aware representations can be used to competitively predict user-review ratings based on a sentence-level opinion predictor.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Garcia2018b</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Garcia, Alexandre and Essid, Slim and Clavel, Chloe and DAlche-Buc, Florence}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Structured Output Learning with Abstention: Application to Accurate Opinion Prediction}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Machine Learning (ICML)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Stockholm, Sweeden}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Parekh2018b" class="col-sm-8"> <div class="title">WEAKLY SUPERVISED REPRESENTATION LEARNING FOR UNSYNCHRONIZED AUDIO-VISUAL EVENTS</div> <div class="author"> S. Parekh , <em>S. Essid</em>, A. Ozerov , Q. Duong , P. Perez , and G. Richard </div> <div class="periodical"> <em>In CVPR Workshop on Sight and Sound (WSS)</em> , Jun 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Parekh2018b</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Parekh, Sanjeel and Essid, Slim and Ozerov, Alexey and Duong, Quang-Khanh-Ngoc and Perez, Patrick and Richard, Gael}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{CVPR Workshop on Sight and Sound (WSS)}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Weakly Supervised Representation Learning for Unsynchronized Audio-Visual Events}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Salt Lake City, USA}</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{
    { @inproceedings{Parekh2018b,
      author = {Parekh, Sanjeel and Essid, Slim and Ozerov, Alexey and Duong, Quang-Khanh-Ngoc and Perez, Patrick and Richard, Gael},
      booktitle = {CVPR Workshop on Sight and Sound (WSS)},
      month = jun,
      title = {Weakly Supervised Representation Learning for Unsynchronized Audio-Visual Events},
      year = 2018,
      address = {Salt Lake City, USA}
    }}
  }</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Parekh2018" class="col-sm-8"> <div class="title">WEAKLY SUPERVISED REPRESENTATION LEARNING FOR UNSYNCHRONIZED AUDIO-VISUAL EVENTS</div> <div class="author"> S. Parekh , <em>S. Essid</em>, A. Ozerov , Q. Duong , P. Perez , and G. Richard </div> <div class="periodical"> Apr 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Audio-visual representation learning is an important task from the perspective of designing machines with the ability to understand complex events. To this end, we propose a novel multimodal framework that instantiates multiple instance learning. We show that the learnt representations are useful for classifying events and localizing their characteristic audio-visual elements. The system is trained using only video-level event labels without any timing information. An important feature of our method is its capacity to learn from unsynchronized audio-visual events. We achieve state-of-the-art results on a large-scale dataset of weakly-labeled audio event videos. Visualizations of localized visual regions and audio segments substantiate our system s efficacy, especially when dealing with noisy situations where modality-specific cues appear asynchronously.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@techreport</span><span class="p">{</span><span class="nl">Parekh2018</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">arxivid</span> <span class="p">=</span> <span class="s">{1804.07345}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{arXiv:1804.07345}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Parekh, Sanjeel and Essid, Slim and Ozerov, Alexey and Duong, Quang-Khanh-Ngoc and Perez, Patrick and Richard, Gael}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{1804.07345}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Weakly Supervised Representation Learning for Unsynchronized Audio-Visual Events}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://arxiv.org/abs/1804.07345}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Garcia2018" class="col-sm-8"> <div class="title">STRUCTURED OUTPUT LEARNING WITH ABSTENTION: APPLICATION TO ACCURATE OPINION PREDICTION</div> <div class="author"> A. Garcia , <em>S. Essid</em>, C. Clavel , and F. DAlche-Buc </div> <div class="periodical"> Mar 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Motivated by Supervised Opinion Analysis, we propose a novel framework devoted to Structured Output Learning with Abstention (SOLA). The structure prediction model is able to abstain from predicting some labels in the structured output at a cost chosen by the user in a flexible way. For that purpose, we decompose the problem into the learning of a pair of predictors, one devoted to structured abstention and the other, to structured output prediction. To compare fully labeled training data with predictions potentially containing abstentions, we define a wide class of asymmetric abstention-aware losses. Learning is achieved by surrogate regression in an appropriate feature space while prediction with abstention is performed by solving a new pre-image problem. Thus, SOLA extends recent ideas about Structured Output Prediction via surrogate problems and calibration theory and enjoys statistical guarantees on the resulting excess risk. Instantiated on a hierarchical abstention-aware loss, SOLA is shown to be relevant for fine-grained opinion mining and gives state-of-the-art results on this task. Moreover, the abstention-aware representations can be used to competitively predict user-review ratings based on a sentence-level opinion predictor.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@techreport</span><span class="p">{</span><span class="nl">Garcia2018</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">arxivid</span> <span class="p">=</span> <span class="s">{1803.08355}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{arXiv:1803.08355}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Garcia, Alexandre and Essid, Slim and Clavel, Chloe and DAlche-Buc, Florence}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{1803.08355}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Structured Output Learning with Abstention: Application to Accurate Opinion Prediction}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://arxiv.org/abs/1803.08355}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="schiratti:hal-01724272" class="col-sm-8"> <div class="title">AN ENSEMBLE LEARNING APPROACH TO DETECT EPILEPTIC SEIZURES FROM LONG INTRACRANIAL EEG RECORDINGS</div> <div class="author"> J. Schiratti , J. Le Douget , M. Le Van Quyen , <em>S. Essid</em>, and A. Gramfort </div> <div class="periodical"> <em>In International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</em> , Apr 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://hal.archives-ouvertes.fr/hal-01724272/file/ICASSP.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">schiratti:hal-01724272</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An Ensemble Learning Approach to Detect Epileptic Seizures from Long Intracranial EEG Recordings}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Schiratti, Jean-Baptiste and Le Douget, Jean-Eudes and Le Van Quyen, Michel and Essid, Slim and Gramfort, Alexandre}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://hal.archives-ouvertes.fr/hal-01724272}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Acoustics, Speech, and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Calgary, Canada}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Intracranial EEG ; Epilepsy and seizures ; Machine learning}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="BARRIERE-18" class="col-sm-8"> <div class="title">ATTITUDE CLASSIFICATION IN ADJACENCY PAIRS OF A HUMAN-AGENT INTERACTION WITH HIDDEN CONDITIONAL RANDOM FIELDS</div> <div class="author"> V. Barriere , C. Clavel , and <em>S. Essid</em> </div> <div class="periodical"> <em>In International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</em> , Apr 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">BARRIERE-18</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Barriere, Valentin and Clavel, Chloe and Essid, Slim}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Attitude Classification in Adjacency Pairs of a Human-Agent Interaction with Hidden Conditional Random Fields}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Acoustics, Speech, and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Calgary, Canada}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings language=en audience=2 state=toappear dept=ids group=s2a id=17744}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SP:brevet18" class="col-sm-8"> <div class="title">METHOD FOR AUDIO-VISUAL EVENTS CLASSIFICATION AND LOCALIZATION, AND CORRESPONDING APPARATUS, COMPUTER READABLE PROGRAM, PRODUCT AND COMPUTER READABLE STORAGE MEDIUM</div> <div class="author"> S. Parekh , <em>S. Essid</em>, A. Ozerov , Q. Duong , P. Perez , and G. Richard </div> <div class="periodical"> <em>Patent Application</em>, Apr 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">SP:brevet18</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Parekh, Sanjeel and Essid, Slim and Ozerov, Alexey and Duong, Quang-Khanh-Ngoc and Perez, Patrick and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Method for audio-visual events classification and localization, and corresponding apparatus, computer readable program, product and computer readable storage medium}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Patent Application}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{180049}</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=brevet language=en state=published dept=ids group=s2a id=18015}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2017</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:ICML17" class="col-sm-8"> <div class="title">MATRIX CO-FACTORISATION AND APPLICATIONS TO MUSIC ANALYSIS</div> <div class="author"> <em>S. Essid</em> </div> <div class="periodical"> <em>In Machine Learning for Music Discovery Workshop, International Conference on Machine Learning (ICML) 2017</em> , Aug 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SE_ICML-17.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SE:ICML17</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Essid, Slim}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Matrix Co-Factorisation and Applications to Music Analysis}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Machine Learning for Music Discovery Workshop, International Conference on Machine Learning (ICML) 2017}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Sydney, Australia}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=invite language=en audience=1 state=published dept=ids group=s2a id=18054}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="bisot:hal-01636627" class="col-sm-8"> <div class="title">NONNEGATIVE FEATURE LEARNING METHODS FOR ACOUSTIC SCENE CLASSIFICATION</div> <div class="author"> V. Bisot , R. Serizel , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>In DCASE 2017 - Workshop on Detection and Classification of Acoustic Scenes and Events</em> , Nov 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/VB_DCASE-17.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">bisot:hal-01636627</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bisot, Victor and Serizel, Romain and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Nonnegative Feature Learning Methods for Acoustic Scene Classification}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{DCASE 2017 - Workshop on Detection and Classification of Acoustic Scenes and Events}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Munich, Germany}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Feature learning;Nonnegative Matrix Factorization;Deep Neural Networks}</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings language=en audience=2 state=published dept=ids group=s2a documentURL=http://biblio.telecom-paristech.fr/cgi-bin/download.cgi?id=17481 id=17481}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SP:brevet17a" class="col-sm-8"> <div class="title">METHOD FOR PROCESSING AN INPUT AUDIO SIGNAL AND CORRESPONDING ELECTRONIC DEVICE</div> <div class="author"> S. Parekh , <em>S. Essid</em>, A. Ozerov , Q. Duong , P. Perez , and G. Richard </div> <div class="periodical"> <em>Patent Application</em>, Nov 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">SP:brevet17a</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Parekh, Sanjeel and Essid, Slim and Ozerov, Alexey and Duong, Quang-Khanh-Ngoc and Perez, Patrick and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Method for Processing an input audio signal and corresponding electronic device}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Patent Application}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{170054}</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=article language=en state=published dept=ids group=s2a id=18014}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Serizel2017" class="col-sm-8"> <div class="title">COMPUTATIONAL ANALYSIS OF SOUND SCENES AND EVENTS</div> <div class="author"> R. Serizel , V. Bisot , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> Nov 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inbook</span><span class="p">{</span><span class="nl">Serizel2017</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Serizel, Romain and Bisot, Victor and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">chapter</span> <span class="p">=</span> <span class="s">{Acoustic Features for Environmental Sound Analysis}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Computational Analysis of Sound Scenes and Events}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Virtanen, Tuomas and Ellis, Dan and Plumbley, Mark}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer International Publishing AG}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Essid2017" class="col-sm-8"> <div class="title">COMPUTATIONAL ANALYSIS OF SOUND SCENES AND EVENTS</div> <div class="author"> <em>S. Essid</em>, S. Parekh , Q. Duong , A. Ozerov , and R. Serizel </div> <div class="periodical"> Nov 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inbook</span><span class="p">{</span><span class="nl">Essid2017</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Essid, Slim and Parekh, Sanjeel and Duong, Quang-Khanh-Ngoc and Ozerov, Alexey and Serizel, Romain}</span><span class="p">,</span>
  <span class="na">chapter</span> <span class="p">=</span> <span class="s">{Multiview Approaches to Event Detection and Scene Analysis}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Computational Analysis of Sound Scenes and Events}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Virtanen, Tuomas and Ellis, Dan and Plumbley, Mark}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer International Publishing AG}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Benyoussef2017" class="col-sm-8"> <div class="title">UE-HRI: A NEW DATASET FOR THE STUDY OF USER ENGAGEMENT IN SPONTANEOUS HUMAN-ROBOT INTERACTIONS</div> <div class="author"> A. Ben Youssef , C. Clavel , <em>S. Essid</em>, M. Bilac , M. Chamoux , and A. Lim </div> <div class="periodical"> <em>In ACM International Conference on Multimodal Interaction</em> , Nov 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/AB_ICMI-17.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Benyoussef2017</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ben Youssef, Atef and Clavel, Chloe and Essid, Slim and Bilac, Miriam and Chamoux, Marine and Lim, Angelica}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ACM International Conference on Multimodal Interaction}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{UE-HRI: A New Dataset for the Study of User Engagement in Spontaneous Human-Robot Interactions}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Glasgow, Scotland}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Bisot2017c" class="col-sm-8"> <div class="title">LEVERAGING DEEP NEURAL NETWORKS WITH NONNEGATIVE REPRESENTATIONS FOR IMPROVED ENVIRONMENTAL SOUND CLASSIFICATION</div> <div class="author"> V. Bisot , R. Serizel , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>In IEEE International Workshop on Machine Learning for Signal Processing (MLSP)</em> , Sep 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/VB_MLSP-17.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Bisot2017c</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bisot, Victor and Serizel, Romain and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Workshop on	Machine Learning for Signal Processing (MLSP)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Leveraging Deep Neural Networks with Nonnegative Representations for Improved Environmental Sound Classification}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Tokyo, Japan}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Parekh2017b" class="col-sm-8"> <div class="title">GUIDING AUDIO SOURCE SEPARATION BY VIDEO OBJECT INFORMATION</div> <div class="author"> S. Parekh , <em>S. Essid</em>, A. Ozerov , Q. Duong , P. Perez , and G. Richard </div> <div class="periodical"> <em>In IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)</em> , Oct 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SP_WASPAA-17.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Parekh2017b</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New Paltz, New York, U.S.A}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Parekh, Sanjeel and Essid, Slim and Ozerov, Alexey and Duong, Quang-Khanh-Ngoc and Perez, Patrick and Richard, Gael}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Guiding Audio Source Separation by Video Object Information}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Conneau2017" class="col-sm-8"> <div class="title">EMOEEG: A NEW MULTIMODAL DATASET FOR DYNAMIC EEG-BASED EMOTION RECOGNITION WITH AUDIOVISUAL ELICITATION</div> <div class="author"> A. Conneau , A. Hajlaoui , M. Chetouani , and <em>S. Essid</em> </div> <div class="periodical"> <em>In The European Signal Processing Conference (EUSIPCO)</em> , Oct 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/AC_EUSIPCO-17.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Conneau2017</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Kos island, Greece}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Conneau, Anne-Claire and Hajlaoui, Ayoub and Chetouani, Mohamed and Essid, Slim}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The European Signal Processing Conference (EUSIPCO)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{EMOEEG: a New Multimodal Dataset for Dynamic EEG-based Emotion Recognition with Audiovisual Elicitation}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Barriere2017" class="col-sm-8"> <div class="title">OPINION DYNAMICS MODELING FOR MOVIE REVIEW TRANSCRIPTS</div> <div class="author"> V. Barriere , C. Clavel , and <em>S. Essid</em> </div> <div class="periodical"> <em>In Interspeech</em> , Oct 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/VB_INTERSPEECH-17.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Barriere2017</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Stockholm, Sweeden}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Barriere, Valentin and Clavel, Chloe and Essid, Slim}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Interspeech}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Opinion Dynamics Modeling for Movie Review Transcripts}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Bisot2017b" class="col-sm-8"> <div class="title">OVERLAPPING SOUND EVENT DETECTION WITH SUPERVISED NONNEGATIVE MATRIX FACTORIZATION</div> <div class="author"> V. Bisot , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> , Oct 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/VB_ICASSP-17.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Bisot2017b</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New Orleans, USA}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bisot, Victor and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Overlapping Sound Event Detection with Supervised Nonnegative Matrix Factorization}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Bisot2017" class="col-sm-8"> <div class="title">FEATURE LEARNING WITH MATRIX FACTORIZATION APPLIED TO ACOUSTIC SCENE CLASSIFICATION</div> <div class="author"> V. Bisot , R. Serizel , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>IEEE Transactions on Audio, Speech, and Language Processing (TASLP)</em>, Oct 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/VB_TASLP-17.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Bisot2017</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bisot, Victor and Serizel, Romain and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Audio, Speech, and Language Processing (TASLP)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Feature Learning with Matrix Factorization Applied to Acoustic Scene Classification}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Serizel2018" class="col-sm-8"> <div class="title">SUPERVISED GROUP NONNEGATIVE MATRIX FACTORISATION WITH SIMILARITY CONSTRAINTS AND APPLICATIONS TO SPEAKER IDENTIFICATION</div> <div class="author"> R. Serizel , V. Bisot , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> , Oct 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/RS_ICASSP-17.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Serizel2018</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New Orleans, USA}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Serizel, Romain and Bisot, Victor and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Supervised Group Nonnegative Matrix Factorisation with Similarity Constraints and Applications to Speaker Identification}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Parekh2017" class="col-sm-8"> <div class="title">MOTION INFORMED AUDIO SOURCE SEPARATION</div> <div class="author"> S. Parekh , <em>S. Essid</em>, A. Ozerov , Q. Duong , P. Perez , and G. Richard </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics Speech and Signal Processing (ICASSP)</em> , Oct 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SP_ICASSP-17.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Parekh2017</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New Orleans, USA}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Parekh, Sanjeel and Essid, Slim and Ozerov, Alexey and Duong, Quang-Khanh-Ngoc and Perez, Patrick and Richard, Gael}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Acoustics Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Motion Informed Audio Source Separation}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2016</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:patent16" class="col-sm-8"> <div class="title">DISPOSITIF A CASQUE AUDIO PERFECTIONNE</div> <div class="author"> <em>S. Essid</em>, and R. Blouet </div> <div class="periodical"> <em>Patent Application</em>, Nov 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/FR3059191A1.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">SE:patent16</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Essid, Slim and Blouet, Raphael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Dispositif a Casque Audio Perfectionne}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Patent Application}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1661324}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Bisot2016b" class="col-sm-8"> <div class="title">SUPERVISED NONNEGATIVE MATRIX FACTORIZATION FOR ACOUSTIC SCENE CLASSIFICATION</div> <div class="author"> V. Bisot , R. Serizel , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>In IEEE international evaluation campaign on detection and classification of acousitc scenes and events (DCASE 2016)</em> , Sep 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/VB_DCASE-16.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Bisot2016b</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bisot, Victor and Serizel, Romain and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Acoustic Scene Classification ; Feature learning ;}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE international evaluation campaign on detection and classification of acousitc scenes and events (DCASE 2016)}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Supervised nonnegative matrix factorization for acoustic scene classification}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SD:ISMIR-16" class="col-sm-8"> <div class="title">DOWNBEAT DETECTION WITH CONDITIONAL RANDOM FIELDS AND DEEP LEARNED FEATURES</div> <div class="author"> S. Durand , and <em>S. Essid</em> </div> <div class="periodical"> <em>In The 17th International Society for Music Information Retrieval Conference (ISMIR)</em> , Aug 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SD_ISMIR-16.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SD:ISMIR-16</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Downbeat Detection with Conditional Random Fields and Deep Learned Features}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Durand, Simon and Essid, Slim}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The 17th International Society for Music Information Retrieval Conference (ISMIR)}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York City, USA}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="RS:MLSP-2016" class="col-sm-8"> <div class="title">MINI-BATCH STOCHASTIC APPROACHES FOR ACCELERATED MULTIPLICATIVE UPDATES IN NONNEGATIVE MATRIX FACTORISATION WITH BETA-DIVERGENCE</div> <div class="author"> R. Serizel , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>In IEEE International Workshop on Machine Learning for Signal Processing (MLSP)</em> , Sep 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/RS_MLSP-16.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">RS:MLSP-2016</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Serizel, Romain and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Mini-batch stochastic approaches for accelerated multiplicative updates in nonnegative matrix factorisation with beta-divergence}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Workshop on Machine Learning for Signal Processing (MLSP)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Nonnegative matrix factorisation, GPGPU, multiplicative rules, online learning}</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings language=en audience=2 state=submitted dept=tsi group=aao      documentURL=http://biblio.telecom-paristech.fr/cgi-bin/download.cgi?id=16155 id=16155}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="RS:ICIP-2016" class="col-sm-8"> <div class="title">MACHINE LISTENING TECHNIQUES AS A COMPLEMENT TO VIDEO IMAGE ANALYSIS IN FORENSICS</div> <div class="author"> R. Serizel , V. Bisot , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>In The International Conference on Image Processing (ICIP)</em> , Oct 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/RS_ICIP-16.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">RS:ICIP-2016</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Serizel, Romain and Bisot, Victor and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Machine listening techniques as a complement to video image analysis in forensics}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The International Conference on Image Processing (ICIP)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings language=en audience=2 state=toappear dept=tsi group=aao documentURL=http://biblio.telecom-paristech.fr/cgi-bin/download.cgi?id=16154 id=16154}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Bisot2016" class="col-sm-8"> <div class="title">ACOUSTIC SCENE CLASSIFICATION WITH MATRIX FACTORIZATION FOR UNSUPERVISED FEATURE LEARNING</div> <div class="author"> V. Bisot , R. Serizel , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> , Mar 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/VB_ICASSP-16.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Bisot2016</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bisot, Victor and Serizel, Romain and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Acoustic scene classification with matrix factorization for unsupervised feature learning}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Shanghai, China}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Acoustic scene classification, unsupervised feature learning,   matrix factorization}</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings language=en audience=2 state=toappear dept=tsi group=aao id=15948}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Serizel2016a" class="col-sm-8"> <div class="title">GROUP NONNEGATIVE MATRIX FACTORISATION WITH SPEAKER AND SESSION VARIABILITY COMPENSATION FOR SPEAKER IDENTIFICATION</div> <div class="author"> R. Serizel , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> , Mar 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/RS_ICASSP-16.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Serizel2016a</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Serizel, Romain and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Group nonnegative matrix factorisation with speaker and session variability compensation for speaker identification}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Shanghai, China}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Nonnegative matrix factorisation, spectrogram factorisation, feature learning, speaker variability, speaker identification}</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings language=en audience=2 state=toappear dept=tsi group=aao documentURL=http://biblio.telecom-paristech.fr/cgi-bin/download.cgi?id=15957 id=15957}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2015</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:hdr" class="col-sm-8"> <div class="title">CONTRIBUTIONS IN MACHINE LEARNING FOR MULTIMODAL DATA ANALYSIS: METHODS, ALGORITHMS AND SYSTEMS FOR TEMPORALLY STRUCTURED DATA</div> <div class="author"> <em>S. Essid</em> </div> <div class="periodical"> <em>Université Pierre et Marie Curie</em> , Sep 2015 </div> <div class="periodical"> Habilitation Thesis </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@phdthesis</span><span class="p">{</span><span class="nl">SE:hdr</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Essid, Slim}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Contributions in Machine Learning for Multimodal Data Analysis: Methods, Algorithms and Systems for Temporally Structured Data}</span><span class="p">,</span>
  <span class="na">school</span> <span class="p">=</span> <span class="s">{Universit\&amp;eacute; Pierre et Marie Curie}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Habilitation Thesis}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Masurelle2015" class="col-sm-8"> <div class="title">TPT-DANCE&amp;ACTIONS : UN CORPUS MULTIMODAL D’ACTIVITES HUMAINES</div> <div class="author"> A. Masurelle , A. Sekkat , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>Revue Traitement du Signal</em>, Sep 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/AM_TS-15.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Masurelle2015</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{TPT-Dance&amp;Actions : un corpus multimodal d’activites humaines}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Revue Traitement du Signal}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Masurelle, Aymeric and Sekkat, A. Rida and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Bittner2015" class="col-sm-8"> <div class="title">MELODY EXTRACTION BY CONTOUR CLASSIFICATION</div> <div class="author"> R. Bittner , J. Salmon , <em>S. Essid</em>, and J. Bello </div> <div class="periodical"> <em>In International Conference on Music Information Retrieval (ISMIR)</em> , Sep 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/RB_ISMIR-15.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Bittner2015</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bittner, Rachel and Salmon, Justin and Essid, Slim and Bello, J. P.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Music Information Retrieval (ISMIR)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Melody Extraction by Contour Classification}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Malaga, Spain}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Bisot2015" class="col-sm-8"> <div class="title">HOG AND SUBBAND POWER DISTRIBUTION IMAGE FEATURES FOR ACOUSTIC SCENE CLASSIFICATION</div> <div class="author"> V. Bisot , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>In European Signal Processing Conference (EUSIPCO)</em> , Sep 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/VB_EUSIPCO-15.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Bisot2015</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bisot, Victor and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{European Signal Processing Conference (EUSIPCO)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{HOG and subband power distribution image features for acoustic scene classification}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Nice, France}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="TF:ICASSP-15" class="col-sm-8"> <div class="title">A CONDITIONAL RANDOM FIELD SYSTEM FOR BEAT TRACKING</div> <div class="author"> T. Fillon , C. Joder , S. Durand , and <em>S. Essid</em> </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> , Apr 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/TF_ICASSP-15.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TF:ICASSP-15</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fillon, Thomas and Joder, Cyril and Durand, Simon and Essid, Slim}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Conditional Random Field System for Beat Tracking}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Brisbane, Australia}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings language=en audience=2 state=toappear dept=tsi group=aao id=15366}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2014</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Seichepine_Essid_Fevotte_Cappe_2014" class="col-sm-8"> <div class="title">SOFT NONNEGATIVE MATRIX CO-FACTORIZATION</div> <div class="author"> N. Seichepine , <em>S. Essid</em>, C. Fevotte , and O. Cappe </div> <div class="periodical"> <em>IEEE Transactions on Signal Processing</em>, Apr 2014 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/NS_TSP-14.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Seichepine_Essid_Fevotte_Cappe_2014</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Soft nonnegative matrix co-factorization}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{PP}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6908018}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TSP.2014.2360141}</span><span class="p">,</span>
  <span class="na">abstractnote</span> <span class="p">=</span> <span class="s">{This work introduces a new framework for nonnegative matrix factorization (NMF) in multisensor or multimodal data configurations, where taking into account the mutual dependence that exists between the related parallel streams of data is expected to improve performance. In contrast with previous works that focused on co-factorization methods  where some factors are shared by the different modalities we propose a soft co-factorization scheme which accounts for possible local discrepancies across modalities or channels. This objective is formalized as an optimization problem where concurrent factorizations are jointly performed while being tied by a coupling term that penalizes differences between the related factor matrices associated with different modalities. We provide majorization-minimization (MM) algorithms for three common measures of fit, the squared Euclidean norm, the Kullback-Leibler divergence and the Itakura-Saito divergence, and two possible coupling variants, using either the l1 or the squared Euclidean norm of differences. The approach is shown to achieve promising performance in two audio-related tasks: multimodal speaker diarization using audiovisual data and audio source separation using stereo data.}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{99}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Signal Processing}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Seichepine, Nicolas and Essid, Slim and Fevotte, Cedric and Cappe, Olivier}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2014}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="NS:ICASSP-14" class="col-sm-8"> <div class="title">PIECEWISE CONSTANT NONNEGATIVE MATRIX FACTORIZATION</div> <div class="author"> N. Seichepine , <em>S. Essid</em>, C. Fevotte , and O. Cappe </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</em> , May 2014 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/NS_ICASSP-14.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">NS:ICASSP-14</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Seichepine, Nicolas and Essid, Slim and Fevotte, Cedric and Cappe, Olivier}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Piecewise constant Nonnegative matrix factorization}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Florence, Italy}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2014}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="AC:ICASSP-14" class="col-sm-8"> <div class="title">ASSESSMENT OF NEW SPECTRAL FEATURES FOR EEG-BASED EMOTION RECOGNITION</div> <div class="author"> A. Conneau , and <em>S. Essid</em> </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</em> , May 2014 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/AC_ICASSP-14.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">AC:ICASSP-14</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Conneau, Anne-Claire and Essid, Slim}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Assessment of new spectral features for EEG-based emotion recognition}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Florence, Italy}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2014}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="AM:ICASSP-14" class="col-sm-8"> <div class="title">GESTURE RECOGNITION USING A NMF-BASED REPRESENTATION OF MOTION-TRACES EXTRACTED FROM DEPTH SILHOUETTES</div> <div class="author"> A. Masurelle , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</em> , May 2014 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/AM_ICASSP-14.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">AM:ICASSP-14</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Masurelle, Aymeric and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Gesture recognition using a NMF-based representation of motion-traces extracted from depth silhouettes}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Florence, Italy}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2014}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2013</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="gretsi-13" class="col-sm-8"> <div class="title">CO-FACTORISATION DOUCE EN MATRICES NON-NEGATIVES. APPLICATION AU REGROUPEMENT MULTIMODAL DE LOCUTEURS</div> <div class="author"> N. Seichepine , <em>S. Essid</em>, C. Fevotte , and O. Cappe </div> <div class="periodical"> <em>In GRETSI</em> , Sep 2013 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">gretsi-13</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Seichepine, Nicolas and Essid, Slim and Fevotte, Cedric and Cappe, Olivier}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Co-factorisation douce en matrices non-negatives. Application au regroupement multimodal de locuteurs}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{GRETSI}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Brest, France}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2013}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{NMF, multimodal}</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings language=fr audience=1 state=toappear dept=tsi group=aao,sta id=14269}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="CD:MLSP-13" class="col-sm-8"> <div class="title">NONNEGATIVE TENSOR FACTORIZATION FOR SINGLE-CHANNEL EEG ARTIFACT REJECTION</div> <div class="author"> C. Damon , A. Liutkus , A. Gramfort , and <em>S. Essid</em> </div> <div class="periodical"> <em>In IEEE International Workshop on Machine Learning for Signal Processing</em> , Sep 2013 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/CD_MLSP-13.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">CD:MLSP-13</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Damon, Cecilia and Liutkus, Antoine and Gramfort, Alexandre and Essid, Slim}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Nonnegative Tensor Factorization for Single-Channel EEG Artifact Rejection}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Workshop on Machine Learning for Signal Processing}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Southampton, UK}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2013}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{EEG, NTF, NMF}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="RF:Wiamis2013" class="col-sm-8"> <div class="title">EXPLORING NEW FEATURES FOR MUSIC CLASSIFICATION</div> <div class="author"> R. Foucard , <em>S. Essid</em>, G. Richard , and M. Lagrange </div> <div class="periodical"> <em>In International Workshop on Image and Audio Analysis for Multimedia Interactive Services (WIAMIS)</em> , Jul 2013 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/RF_WIAMIS-13.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">RF:Wiamis2013</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Foucard, Remi and Essid, Slim and Richard, Gael and Lagrange, Mathieu}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Exploring new features for music classification}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Workshop on Image and Audio Analysis for Multimedia Interactive Services (WIAMIS)}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Paris, France}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2013}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="AM:WIAMIS-13" class="col-sm-8"> <div class="title">MULTIMODAL CLASSIFICATION OF DANCE MOVEMENTS USING BODY JOINT TRAJECTORIES AND STEP SOUNDS</div> <div class="author"> A. Masurelle , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>In International Workshop on Image and Audio Analysis for Multimedia Interactive Services (WIAMIS)</em> , Jul 2013 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/AM_WIAMIS-13.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">AM:WIAMIS-13</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Masurelle, Aymeric and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Multimodal classification of dance movements using body joint trajectories and step sounds}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Workshop on Image and Audio Analysis for Multimedia Interactive Services (WIAMIS)}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Paris, France}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2013}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Dremeau2013a" class="col-sm-8"> <div class="title">PROBABILISTIC DANCE PERFORMANCE ALIGNMENT BY FUSION OF MULTIMODAL FEATURES </div> <div class="author"> A. Dremeau , and <em>S. Essid</em> </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</em> , May 2013 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/AD_ICASSP-13.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Dremeau2013a</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dremeau, Angelique and Essid, Slim}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Probabilistic dance performance alignment by fusion of multimodal features }</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Vancouver, Canada}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2013}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings language=en audience=2 state=toappear dept=tsi group=aao id=13252}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="ICASSP-13-SEICHEPINE" class="col-sm-8"> <div class="title">SOFT NONNEGATIVE MATRIX CO-FACTORIZATION WITH APPLICATION TO MULTIMODAL SPEAKER DIARIZATION</div> <div class="author"> N. Seichepine , <em>S. Essid</em>, C. Fevotte , and O. Cappe </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</em> , May 2013 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/NS_ICASSP-13.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ICASSP-13-SEICHEPINE</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Seichepine, Nicolas and Essid, Slim and Fevotte, Cedric and Cappe, Olivier}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Soft Nonnegative Matrix Co-factorization with Application to Multimodal Speaker Diarization}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Vancouver}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2013}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Nonnegative matrix factorization, cofactorization, multimodality, speaker diarization}</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings language=en audience=2 state=toappear dept=tsi group=aao,sta id=13313}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="CD:ICASSP-13" class="col-sm-8"> <div class="title">NONNEGATIVE MATRIX FACTORIZATION FOR SINGLE-CHANNEL EEG ARTIFACT REJECTION</div> <div class="author"> C. Damon , A. Liutkus , A. Gramfort , and <em>S. Essid</em> </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP) </em> , May 2013 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/CD_ICASSP-13.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">CD:ICASSP-13</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Damon, Cecilia and Liutkus, Antoine and Gramfort, Alexandre and Essid, Slim}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Nonnegative Matrix Factorization for Single-Channel EEG Artifact Rejection}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP) }</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Vancouver, Canada}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2013}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings language=en audience=2 state=toappear dept=tsi group=aao id=13264}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="FV:TM-12" class="col-sm-8"> <div class="title">A MULTIMODAL APPROACH TO SPEAKER DIARIZATION ON TV TALK-SHOWS</div> <div class="author"> F. Vallet , <em>S. Essid</em>, and J. Carrive </div> <div class="periodical"> <em>IEEE Transactions on Multimedia</em>, May 2013 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/FV_TM-13.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>In this article, we propose solutions to the problem of speaker diarization of TV talk-shows, a problem for which adapted multimodal approaches, relying on other streams of data than only audio, remain largely under exploited. Hence we propose an original system that leverages prior knowledge on the structure of this type of content, especially the visual information relating to the active speakers, for an improved diarization performance. The architecture of this system can be decomposed into two main stages. First a reliable training set is created, in an unsupervised fashion, for each participant of the TV program being processed. This data is assembled by the association of visual and audio descriptors carefully selected in a clustering cascade. Then, Support Vector Machines are used for the classification of the speech data (of a given TV program). The performance of this new architecture is assessed on two French talk-show collections: Le Grand Échiquier and On na pas tout dit. The results show that our new system outperforms state-of-the-art methods, thus evidencing the effectiveness of kernel-based methods, as well as visual cues, in multimodal approaches to speaker diarization of challenging contents such as TV talk-shows.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">FV:TM-12</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Vallet, F. and Essid, Slim and Carrive, J.}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Multimedia}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Multimodal Approach to Speaker Diarization on TV Talk-Shows}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2013}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{15}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{3}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{509-520}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{speaker recognition;support vector machines;French talk show collection;TV program;TV talk shows;audio descriptors;clustering cascade;diarization performance;kernel based method;multimodal approach;original system;reliable training set;speaker diarization;speech data;support vector machines;visual descriptors;Cameras;Databases;Microphones;NIST;Speech;TV;Visualization;Fusion;SVM classification;joint audiovisual processing;multimodality;speaker diarization;talk-show;unsupervised learning}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TMM.2012.2233724}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1520-9210}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="CJ:TASLP-13" class="col-sm-8"> <div class="title">LEARNING OPTIMAL FEATURES FOR POLYPHONIC AUDIO-TO-SCORE ALIGNMENT</div> <div class="author"> C. Joder , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>IEEE Transactions on Audio, Speech, and Language Processing</em>, May 2013 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/CJ_TASLP-13.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">CJ:TASLP-13</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Joder, Cyril and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Audio, Speech, and Language Processing}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning Optimal Features for Polyphonic Audio-to-Score Alignment}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2013}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{21}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2118-2128}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{audio signal processing;maximum likelihood estimation;signal representation;CQT-based representation;audio observations;conditional random fields model;discriminative framework;feature functions design;heuristic mappings;learning optimal features;linear transformation;maximum likelihood criterion;musical recording;polyphonic audio-to-score alignment;polyphonic music;spectrogram;symbolic representation;symmetric Kull-back-Leibler divergence;template construction;template vectors;temporal constraints;Music information retrieval;audio-to-score alignment;conditional random fields;discriminative learning}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TASL.2013.2266794}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1558-7916}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:TMM-12" class="col-sm-8"> <div class="title">SMOOTH NONNEGATIVE MATRIX FACTORIZATION FOR UNSUPERVISED AUDIOVISUAL DOCUMENT STRUCTURING</div> <div class="author"> <em>S. Essid</em>, and C. Fevotte </div> <div class="periodical"> <em>IEEE Transactions on Multimedia</em>, May 2013 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SE_TM-12.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">SE:TMM-12</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Essid, Slim and Fevotte, Cedric}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Multimedia}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Smooth Nonnegative Matrix Factorization for Unsupervised Audiovisual Document Structuring}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2013}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{15}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{415-425}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{audio signal processing;document handling;hidden Markov models;matrix decomposition;minimisation;unsupervised learning;video databases;video signal processing;Kullback-Leibler divergence;NMF algorithm;audio modality;audio speaker diarization;cost function;hidden Markov model;histogram-of-count;latent structuring pattern;majorization-minimization technique;person-oriented video structuring task;political debate video database;smooth nonnegative matrix factorization;temporal smoothness constraint;unsupervised audiovisual document structuring;visual modality;Data models;Feature extraction;Histograms;Indexing;Telecommunications;Visualization;Vocabulary;Bag of features;content structuring;indexing;machine learning;matrix factorization;unsupervised classification;videos}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TMM.2012.2228474}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1520-9210}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2012</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="AL:ACM-12" class="col-sm-8"> <div class="title">ANALYSIS OF DANCE MOVEMENTS USING GAUSSIAN PROCESSES</div> <div class="author"> A. Liutkus , A. Dremeau , D. Alexiadis , <em>S. Essid</em>, and P. Daras </div> <div class="periodical"> <em>In ACM Multimedia</em> , Nov 2012 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">AL:ACM-12</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liutkus, Antoine and Dremeau, Angelique and Alexiadis, D. and Essid, Slim and Daras, Petros}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Analysis of dance movements using Gaussian processes}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ACM Multimedia}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Nara, Japan}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2012}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://hal.inria.fr/hal-00718791}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:ICIP-12" class="col-sm-8"> <div class="title">DECOMPOSING THE VIDEO EDITING STRUCTURE OF A TALK-SHOW USING NONNEGATIVE MATRIX FACTORIZATION</div> <div class="author"> <em>S. Essid</em>, and C. Fevotte </div> <div class="periodical"> <em>In International Conference on Image Processing (ICIP)</em> , Oct 2012 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SE:ICIP-12</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Essid, Slim and Fevotte, Cedric}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Decomposing the Video Editing Structure of a Talk-show using Nonnegative Matrix Factorization}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Image Processing (ICIP)}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Orlando, FL, USA}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2012}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings language=en audience=2 state=toappear dept=tsi group=aao id=12528}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:DFU-12" class="col-sm-8"> <div class="title">MULTIMODAL MUSIC PROCESSING</div> <div class="author"> <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> Oct 2012 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SE_DFU-12.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inbook</span><span class="p">{</span><span class="nl">SE:DFU-12</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">chapter</span> <span class="p">=</span> <span class="s">{Fusion of Multimodal Information in Music Content Analysis}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Multimodal Music Processing}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{37--52}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Dagstuhl Follow-Ups}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-939897-37-8}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1868-8977}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2012}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{3}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Muller, Meinard and Goto, Masataka and Schedl, Markus}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Dagstuhl, Germany}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://drops.dagstuhl.de/opus/volltexte/2012/3465}</span><span class="p">,</span>
  <span class="na">urn</span> <span class="p">=</span> <span class="s">{urn:nbn:de:0030-drops-34652}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{http://dx.doi.org/10.4230/DFU.Vol3.11041.37}</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{Keywords: Multimodal music processing, music signals indexing and transcription, information fusion, audio, video}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:ICMI-12" class="col-sm-8"> <div class="title">A MULTI-MODAL DANCE CORPUS FOR RESEARCH INTO INTERACTION BETWEEN HUMANS IN VIRTUAL ENVIRONMENTS</div> <div class="author"> <em>S. Essid</em>, X. Lin , M. Gowing , G. Kordelas , A. Aksay , P. Kelly , T. Fillon , Q. Zhang , A. Dielmann , V. Kitanovski , R. Tournemenne , A. Masurelle , E. Izquierdo , N. OConnor , P. Daras , and G. Richard </div> <div class="periodical"> <em>Journal on Multimodal User Interfaces: Special issue on multimodal corpora</em>, Oct 2012 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SE_ICMI-12.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">SE:ICMI-12</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Essid, Slim and Lin, X. and Gowing, M. and Kordelas, G. and Aksay, A. and Kelly, P. and Fillon, Thomas and Zhang, Q. and Dielmann, A. and Kitanovski, V. and Tournemenne, R. and Masurelle, Aymeric and Izquierdo, E. and OConnor, N. E. and Daras, Petros and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A multi-modal dance corpus for research into interaction between humans in virtual environments}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal on Multimodal User Interfaces: Special issue on multimodal corpora}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2012}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:ICASSP-12b" class="col-sm-8"> <div class="title">AN ADVANCED VIRTUAL DANCE PERFORMANCE EVALUATOR</div> <div class="author"> <em>S. Essid</em>, D. Alexiadis , R. Tournemenne , M. Gowing , P. Kelly , D. Monhagan , P. Daras , A. Dremeau , and N. OConnor </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech and Signal Processing</em> , Mar 2012 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SE_ICASSP-12.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SE:ICASSP-12b</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Essid, Slim and Alexiadis, D. and Tournemenne, R. and Gowing, M. and Kelly, P. and Monhagan, D. and Daras, Petros and Dremeau, Angelique and OConnor, N. E.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An Advanced Virtual Dance Performance Evaluator}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Acoustics, Speech and Signal Processing}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Kyoto, Japan}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2012}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings language=en audience=2 state=toappear project=audiosig dept=tsi group=aao id=12271}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:ICASSP-12" class="col-sm-8"> <div class="title">A SINGLE-CLASS SVM BASED ALGORITHM FOR COMPUTING AN IDENTIFIABLE NMF</div> <div class="author"> <em>S. Essid</em> </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech and Signal Processing</em> , Mar 2012 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SE_ICASSP-12b.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SE:ICASSP-12</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Essid, Slim}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Single-class SVM Based Algorithm For Computing An Identifiable Nmf}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Acoustics, Speech and Signal Processing}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Kyoto, Japan}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2012}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings language=en audience=2 state=toappear project=audiosig dept=tsi group=aao id=12270}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="RF:ICASSP-12" class="col-sm-8"> <div class="title">A REGRESSIVE BOOSTING APPROACH TO AUTOMATIC AUDIO TAGGING BASED ON SOFT ANNOTATOR FUSION</div> <div class="author"> R. Foucard , <em>S. Essid</em>, M. Lagrange , and G. Richard </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> , Mar 2012 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/RF_ICASSP-12.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">RF:ICASSP-12</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Foucard, Remi and Essid, Slim and Lagrange, Mathieu and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Regressive Boosting Approach To Automatic Audio Tagging Based On Soft Annotator Fusion}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Kyoto, Japan}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2012}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings language=en audience=2 state=toappear project=audiosig dept=tsi group=aao id=12269}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2011</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:ICMI-11" class="col-sm-8"> <div class="title">A MULTIMODAL DANCE CORPUS FOR RESEARCH INTO REAL-TIME INTERACTION BETWEEN HUMANS IN ONLINE VIRTUAL ENVIRONMENTS </div> <div class="author"> <em>S. Essid</em>, X. Lin , M. Gowing , G. Kordelas , A. Aksay , P. Kelly , T. Fillon , Q. Zhang , A. Dielmann , V. Kitanovski , R. Tournemenne , N. OConnor , P. Daras , and G. Richard </div> <div class="periodical"> <em>In ICMI Workshop On Multimodal Corpora For Machine Learning</em> , Nov 2011 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SE_ICMI-11.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SE:ICMI-11</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Essid, Slim and Lin, X. and Gowing, M. and Kordelas, G. and Aksay, A. and Kelly, P. and Fillon, Thomas and Zhang, Q. and Dielmann, A. and Kitanovski, V. and Tournemenne, R. and OConnor, N. E. and Daras, Petros and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A multimodal dance corpus for research into real-time interaction between humans in online virtual environments }</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICMI Workshop On Multimodal Corpora For Machine Learning}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Alicante, Spain}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2011}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings language=en audience=2 state=published project=audiosig dept=tsi group=aao id=12272}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:ACM-MM-GC-2011" class="col-sm-8"> <div class="title">AN AUDIO-DRIVEN VIRTUAL DANCE-TEACHING ASSISTANT</div> <div class="author"> <em>S. Essid</em>, Y. Grenier , M. Maazaoui , G. Richard , and R. Tournemenne </div> <div class="periodical"> <em>In ACM Multimedia</em> , Nov 2011 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SE_ACM-11.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SE:ACM-MM-GC-2011</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Essid, Slim and Grenier, Yves and Maazaoui, Mounira and Richard, Gael and Tournemenne, R.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An audio-driven virtual dance-teaching assistant}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ACM Multimedia}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Scottsdale, Arizona, USA}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2011}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings language=fr audience=1 state=toappear project= dept=tsi group=aao id=11561}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="CC:ACM-MM-GC-2011" class="col-sm-8"> <div class="title">ENHANCED VISUALISATION OF DANCE PERFORMANCE FROM AUTOMATICALLY SYNCHRONISED MULTIMODAL RECORDINGS</div> <div class="author"> M. Gowing , P. Kelly , N. OConnor , E. Izquierdo , V. Kitanovski , X. Lin , Q. Zhang , C. Concolato , <em>S. Essid</em>, J. Feuvre , and R. Tournemenne </div> <div class="periodical"> <em>In ACM Multimedia</em> , Nov 2011 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/CC_ACM-11.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">CC:ACM-MM-GC-2011</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Gowing, M. and Kelly, P. and OConnor, N. E. and Izquierdo, E. and Kitanovski, V. and Lin, X. and Zhang, Q. and Concolato, C. and Essid, Slim and Feuvre, J. Le and Tournemenne, R.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Enhanced Visualisation of Dance Performance from Automatically Synchronised Multimodal Recordings}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ACM Multimedia}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Scottsdale, Arizona, USA}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2011}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings language=en audience=2 state=toappear project=m2 dept=tsi group=aao,mm id=11552}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SG:ISMIR-11" class="col-sm-8"> <div class="title">AN INTERACTIVE SYSTEM FOR ELECTRO-ACOUSTIC MUSIC ANALYSIS</div> <div class="author"> S. Gulluni , <em>S. Essid</em>, O. Buisson , and G. Richard </div> <div class="periodical"> <em>In International Conference on Music Information Retrieval (ISMIR)</em> , Oct 2011 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SG_ISMIR-11.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SG:ISMIR-11</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Gulluni, S. and Essid, Slim and Buisson, O. and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An interactive system for electro-acoustic music analysis}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Music Information Retrieval (ISMIR)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2011}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Miami, U.S.A}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="RF:ISMIR-11" class="col-sm-8"> <div class="title">MULTI-SCALE TEMPORAL FUSION BY BOOSTING FOR MUSIC CLASSIFICATION</div> <div class="author"> R. Foucard , <em>S. Essid</em>, M. Lagrange , and G. Richard </div> <div class="periodical"> <em>In International Conference on Music Information Retrieval (ISMIR)</em> , Oct 2011 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/RF_ISMIR-11.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">RF:ISMIR-11</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Foucard, Remi and Essid, Slim and Lagrange, Mathieu and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Multi-scale temporal fusion by boosting for music classification}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Music Information Retrieval (ISMIR)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2011}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Miami, U.S.A}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="CJ:WASPAA-11" class="col-sm-8"> <div class="title">OPTIMIZING THE MAPPING FROM A SYMBOLIC TO AN AUDIO REPRESENTATION FOR MUSIC-TO-SCORE ALIGNMENT</div> <div class="author"> C. Joder , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>In IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)</em> , Oct 2011 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/CJ_WASPAA-11.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">CJ:WASPAA-11</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Joder, Cyril and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Optimizing the Mapping from a Symbolic to an Audio Representation for Music-to-Score Alignment}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2011}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New Paltz, New York, U.S.A}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:TREP-11" class="col-sm-8"> <div class="title">NONNEGATIVE MATRIX FACTORIZATION FOR UNSUPERVISED AUDIOVISUAL DOCUMENT STRUCTURING</div> <div class="author"> <em>S. Essid</em>, and C. Fevotte </div> <div class="periodical"> Oct 2011 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SE_HAL-11.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@techreport</span><span class="p">{</span><span class="nl">SE:TREP-11</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Essid, Slim and Fevotte, Cedric}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Nonnegative matrix factorization for unsupervised audiovisual document structuring}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2011}</span><span class="p">,</span>
  <span class="na">institution</span> <span class="p">=</span> <span class="s">{HAL}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{hal-00605886}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://hal.archives-ouvertes.fr/hal-00605886/en/}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="GA:IFMGBOOK" class="col-sm-8"> <div class="title">SEMANTIQUE ET MULTIMODALITE EN ANALYSE DE L INFORMATION</div> <div class="author"> G. Adda , G. Chollet , <em>S. Essid</em>, T. Fillon , M. Garnier-Rizet , C. Hory , and L. Beltaifa-Zouari </div> <div class="periodical"> Oct 2011 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inbook</span><span class="p">{</span><span class="nl">GA:IFMGBOOK</span><span class="p">,</span>
  <span class="na">chapter</span> <span class="p">=</span> <span class="s">{Traitement des modalites "audio" et "parole"}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Semantique et multimodalite en analyse de l information}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Hermes/Lavoisier}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2011}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Campedel, Marine and Hoogstel, Pierre}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Adda, G. and Chollet, G. and Essid, Slim and Fillon, Thomas and Garnier-Rizet, M. and Hory, C. and Beltaifa-Zouari, L.}</span><span class="p">,</span>
  <span class="na">owner</span> <span class="p">=</span> <span class="s">{essid}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{2011.02.28}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="FV:TVBOOK-11" class="col-sm-8"> <div class="title">TV CONTENT ANALYSIS: TECHNIQUES AND APPLICATIONS</div> <div class="author"> F. Vallet , <em>S. Essid</em>, J. Carrive , and G. Richard </div> <div class="periodical"> Oct 2011 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inbook</span><span class="p">{</span><span class="nl">FV:TVBOOK-11</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Vallet, F. and Essid, Slim and Carrive, J. and Richard, G.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{TV Content Analysis: Techniques and Applications}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Y. Kompatsiaris, B. Merialdo and Lian, S.}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{CRC Press, Taylor Francis LLC}</span><span class="p">,</span>
  <span class="na">chapter</span> <span class="p">=</span> <span class="s">{High-level TV talk show structuring centered on speakers interventions}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2011}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SG:AES-11" class="col-sm-8"> <div class="title">INTERACTIVE CLASSIFICATION OF SOUND OBJECTS FOR POLYPHONIC ELECTRO-ACOUSTIC MUSIC ANNOTATION</div> <div class="author"> S. Gulluni , <em>S. Essid</em>, O. Buisson , and G. Richard </div> <div class="periodical"> <em>In AES 42nd International Conference</em> , Jul 2011 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SG_AES-11.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SG:AES-11</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Gulluni, S. and Essid, Slim and Buisson, O. and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Interactive Classification of Sound Objects for Polyphonic Electro-Acoustic Music Annotation}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{AES 42nd International Conference}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2011}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Ilmenau, Germany}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="RB:MMABOOK-11" class="col-sm-8"> <div class="title">MULTIMEDIA SEMANTICS: METADATA, ANALYSIS AND INTERACTION</div> <div class="author"> R. Benmokhtar , B. Huet , G. Richard , T. Declerck , and <em>S. Essid</em> </div> <div class="periodical"> Jul 2011 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inbook</span><span class="p">{</span><span class="nl">RB:MMABOOK-11</span><span class="p">,</span>
  <span class="na">chapter</span> <span class="p">=</span> <span class="s">{Feature Extraction for Multimedia Analysis}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Multimedia Semantics: Metadata, Analysis and Interaction}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Wiley}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2011}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{R. Troncy, B. Huet and Schenk, S.}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Benmokhtar, R. and Huet, B. and Richard, Gael and Declerck, T. and Essid, Slim}</span><span class="p">,</span>
  <span class="na">owner</span> <span class="p">=</span> <span class="s">{essid}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{2010.12.20}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:MMABOOK-11" class="col-sm-8"> <div class="title">MULTIMEDIA SEMANTICS: METADATA, ANALYSIS AND INTERACTION</div> <div class="author"> <em>S. Essid</em>, M. Campedel , G. Richard , T. Piatrik , R. Benmokhtar , and B. Huet </div> <div class="periodical"> Jul 2011 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inbook</span><span class="p">{</span><span class="nl">SE:MMABOOK-11</span><span class="p">,</span>
  <span class="na">chapter</span> <span class="p">=</span> <span class="s">{Machine Learning Techniques for Multimedia Analysis}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Multimedia Semantics: Metadata, Analysis and Interaction}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Wiley}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2011}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{R. Troncy, B. Huet and Schenk, S.}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Essid, Slim and Campedel, M. and Richard, Gael and Piatrik, T. and Benmokhtar, R. and Huet, B.}</span><span class="p">,</span>
  <span class="na">owner</span> <span class="p">=</span> <span class="s">{essid}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{2010.12.20}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="CJ:TSALP-2011" class="col-sm-8"> <div class="title">A CONDITIONAL RANDOM FIELD FRAMEWORK FOR ROBUST AND SCALABLE AUDIO-TO-SCORE MATCHING</div> <div class="author"> C. Joder , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>IEEE Transactions on Audio, Speech and Language Processing</em>, Nov 2011 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/CJ_TSALP-11.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">CJ:TSALP-2011</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Joder, Cyril and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Conditional Random Field Framework for Robust and Scalable Audio-to-Score
  	Matching}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Audio, Speech and Language Processing}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{19}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2385 - 2397}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2011}</span><span class="p">,</span>
  <span class="na">owner</span> <span class="p">=</span> <span class="s">{essid}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{2011.02.10}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="CJ:ICASSP-11" class="col-sm-8"> <div class="title">HIDDEN DISCRETE TEMPO MODEL: A TEMPO-AWARE TIMING MODEL FOR AUDIO-TO-SCORE ALIGNMENT</div> <div class="author"> C. Joder , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> , May 2011 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/CJ_ICASSP-11.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">CJ:ICASSP-11</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Joder, Cyril and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hidden Discrete Tempo Model: a Tempo-aware Timing Model for Audio-to-Score
  	Alignment}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Acoustics, Speech and Signal Processing
  	(ICASSP)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2011}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Prague, Czech Republic}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">owner</span> <span class="p">=</span> <span class="s">{essid}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{2011.01.28}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2010</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SB:Eusipco10" class="col-sm-8"> <div class="title">A MULTIMODAL APPROACH TO INITIALISATION FOR TOP-DOWN SPEAKER DIARIZATION OF TELEVISION SHOWS</div> <div class="author"> S. Bozonnet , F. Vallet , N. Evans , <em>S. Essid</em>, J. Carrive , and G. Richard </div> <div class="periodical"> <em>In European Signal Processing Conference (EUSIPCO)</em> , Aug 2010 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SB_EUSIPCO-10.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SB:Eusipco10</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bozonnet, S. and Vallet, F. and Evans, N. and Essid, Slim and Carrive, J. and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A multimodal approach to initialisation for top-down speaker diarization
  	of television shows}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{European Signal Processing Conference (EUSIPCO)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2010}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Allborg, Denmark}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=toappear project=audiosig dept=tsi group=aao
  	id=10394}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{:D\:\\documents\\myPage\\papers\\SB_EUSIPCO-10.pdf:PDF}</span><span class="p">,</span>
  <span class="na">owner</span> <span class="p">=</span> <span class="s">{essid}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{2010.06.24}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="CJ:ACM-2010" class="col-sm-8"> <div class="title">A CONDITIONAL RANDOM FIELD VIEWPOINT OF SYMBOLIC AUDIO-TO-SCORE MATCHING</div> <div class="author"> C. Joder , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>In ACM Multimedia 2010</em> , Oct 2010 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">CJ:ACM-2010</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Joder, Cyril and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Conditional Random Field Viewpoint of Symbolic Audio-to-Score Matching}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ACM Multimedia 2010}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2010}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Florence, Italy}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">owner</span> <span class="p">=</span> <span class="s">{essid}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{2010.07.06}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="CJ:CORESA-2010" class="col-sm-8"> <div class="title">APPROCHE HI&amp;EACUTE;RARCHIQUE POUR UN ALIGNEMENT MUSIQUE-SUR-PARTITION EFFICACE</div> <div class="author"> C. Joder , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>In Compression et Représentation des Signaux Audiovisuels (CORESA)</em> , Oct 2010 </div> <div class="periodical"> Received Young Researcher Award! </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/CJ_CORESA-2010.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">CJ:CORESA-2010</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Joder, Cyril and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Approche hi\&amp;eacute;rarchique pour un alignement musique-sur-partition
  	efficace}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Compression et Repr\&amp;eacute;sentation des Signaux Audiovisuels (CORESA)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2010}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Lyon, France}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Received Young Researcher Award!}</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=toappear project=audiosig dept=tsi group=aao
  	id=10418}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{:D\:\\documents\\myPage\\papers\\CJ_CORESA-10.pdf:PDF}</span><span class="p">,</span>
  <span class="na">owner</span> <span class="p">=</span> <span class="s">{essid}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{2010.06.24}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="CJ:ICASSP-2010" class="col-sm-8"> <div class="title">A COMPARATIVE STUDY OF TONAL ACOUSTIC FEATURES FOR A SYMBOLIC LEVEL MUSIC-TO-SCORE ALIGNMENT</div> <div class="author"> C. Joder , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> , Mar 2010 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/CJ_ICASSP-10.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">CJ:ICASSP-2010</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Joder, Cyril and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Comparative Study of tonal acoustic Features for a Symbolic Level
  	Music-to-Score Alignment}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Acoustics, Speech and Signal Processing
  	(ICASSP)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2010}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Dallas, TX, US}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=toappear project=audiosig dept=tsi group=aao
  	id=10174}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{CJ_ICASSP-2010.pdf:./papers/CJ_ICASSP-10.pdf:PDF}</span><span class="p">,</span>
  <span class="na">owner</span> <span class="p">=</span> <span class="s">{essid}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{2010.03.10}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="CJ:ISMIR-2010" class="col-sm-8"> <div class="title">AN IMPROVED HIERARCHICAL APPROACH FOR MUSIC-TO-SYMBOLIC SCORE ALIGNMENT</div> <div class="author"> C. Joder , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>In International Conference on Music Information Retrieval (ISMIR)</em> , Aug 2010 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/CJ_ISMIR-2010.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">CJ:ISMIR-2010</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Joder, Cyril and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An Improved Hierarchical Approach for Music-to-Symbolic Score Alignment}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Music Information Retrieval (ISMIR)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2010}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Utrecht, The Netherlands}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=toappear project=audiosig dept=tsi group=aao
  	id=10383}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{:D\:\\documents\\myPage\\papers\\CJ_ISMIR-10.pdf:PDF}</span><span class="p">,</span>
  <span class="na">owner</span> <span class="p">=</span> <span class="s">{essid}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{2010.06.24}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="BM:ISMIR10" class="col-sm-8"> <div class="title">YAAFE, AN EASY TO USE AND EFFICIENT AUDIO FEATURE EXTRACTION SOFTWARE</div> <div class="author"> B. Mathieu , <em>S. Essid</em>, T. Fillon , J. Prado , and G. Richard </div> <div class="periodical"> <em>In International Conference on Music Information Retrieval (ISMIR)</em> , Aug 2010 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/BM_ISMIR-10.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">BM:ISMIR10</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mathieu, B. and Essid, Slim and Fillon, Thomas and Prado, J. and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{YAAFE, AN EASY TO USE AND EFFICIENT AUDIO FEATURE EXTRACTION SOFTWARE}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Music Information Retrieval (ISMIR)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2010}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Utrecht, The Netherlands}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=toappear project=audiosig dept=tsi group=aao
  	id=10395}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{:D\:\\documents\\myPage\\papers\\BM_ISMIR-10.pdf:PDF}</span><span class="p">,</span>
  <span class="na">owner</span> <span class="p">=</span> <span class="s">{essid}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{2010.06.24}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="FV:CORESA-10" class="col-sm-8"> <div class="title">DESCRIPTEURS VISUELS ROBUSTES POUR L IDENTIFICATION DE LOCUTEURS DANS DES EMISSIONS TELEVISEES DE TALK-SHOWS</div> <div class="author"> F. Vallet , <em>S. Essid</em>, J. Carrive , and G. Richard </div> <div class="periodical"> <em>In Compression et Représentation des Signaux Audiovisuels (CORESA)</em> , Oct 2010 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/FV_ICIP-10.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">FV:CORESA-10</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Vallet, F. and Essid, Slim and Carrive, J. and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Descripteurs visuels robustes pour l identification de locuteurs
  	dans des emissions televisees de talk-shows}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Compression et Repr\&amp;eacute;sentation des Signaux Audiovisuels (CORESA)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2010}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Lyon, France}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=toappear project=audiosig dept=tsi group=aao
  	id=10393}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{:D\:\\documents\\myPage\\papers\\FV_CORESA-10.pdf:PDF}</span><span class="p">,</span>
  <span class="na">owner</span> <span class="p">=</span> <span class="s">{essid}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{2010.06.24}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="FV:ICIP10" class="col-sm-8"> <div class="title">ROBUST VISUAL FEATURES FOR THE MULTIMODAL IDENTIFICATION OF UNREGISTERED SPEAKERS IN TV TALK-SHOWS</div> <div class="author"> F. Vallet , <em>S. Essid</em>, J. Carrive , and G. Richard </div> <div class="periodical"> <em>In IEEE International Conference on Image Processing (ICIP)</em> , Oct 2010 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/FV_ICIP-10.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">FV:ICIP10</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Vallet, F. and Essid, Slim and Carrive, J. and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{ROBUST VISUAL FEATURES FOR THE MULTIMODAL IDENTIFICATION OF UNREGISTERED
  	SPEAKERS IN TV TALK-SHOWS}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Image Processing (ICIP)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2010}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=toappear project=audiosig dept=tsi group=aao
  	id=10393}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{:./papers/FV_ICIP-10.pdf:PDF}</span><span class="p">,</span>
  <span class="na">owner</span> <span class="p">=</span> <span class="s">{essid}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{2010.06.24}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2009</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SG:MML-09" class="col-sm-8"> <div class="title">INTERACTIVE SEGMENTATION OF ELECTRO-ACOUSTIC MUSIC</div> <div class="author"> S. Gulluni , <em>S. Essid</em>, O. Buisson , E. Favreau , and G. Richard </div> <div class="periodical"> <em>In 2nd International Workshop on Machine Learning and Music (MML - ECML - PKDD)</em> , Sep 2009 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SG_MML-09.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SG:MML-09</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Gulluni, S. and Essid, Slim and Buisson, O. and Favreau, E. and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Interactive Segmentation of Electro-Acoustic Music}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2nd International Workshop on Machine Learning and Music (MML - ECML
  	- PKDD)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2009}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Bled, Slovenia}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=published project=audiosig dept=tsi
  	group=aao id=10303}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{SG_MML-09.pdf:./papers/SG_MML-09.pdf:PDF}</span><span class="p">,</span>
  <span class="na">owner</span> <span class="p">=</span> <span class="s">{essid}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{2010.03.10}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="CJ:GRETSI-09" class="col-sm-8"> <div class="title">ETUDE DES DESCRIPTEURS ACOUSTIQUES POUR L ALIGNEMENT TEMPOREL AUDIO-SUR-PARTITION MUSICALE</div> <div class="author"> C. Joder , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>In GRETSI</em> , Sep 2009 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/CJ_GRETSI-09.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">CJ:GRETSI-09</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Joder, Cyril and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Etude des descripteurs acoustiques pour l alignement temporel audio-sur-partition
  	musicale}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{GRETSI}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2009}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Dijon}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=published project=audiosig dept=tsi
  	group=aao id=9946}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{CJ_GRETSI-09.pdf:./papers/CJ_GRETSI-09.pdf:PDF}</span><span class="p">,</span>
  <span class="na">owner</span> <span class="p">=</span> <span class="s">{essid}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{2010.03.10}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="CJ:TASLP-08" class="col-sm-8"> <div class="title">TEMPORAL INTEGRATION FOR AUDIO CLASSIFICATION WITH APPLICATION TO MUSICAL INSTRUMENT CLASSIFICATION</div> <div class="author"> C. Joder , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>IEEE Transactions on Audio, Speech and Language Processing</em>, Jan 2009 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/CJ_TASLP-09.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">CJ:TASLP-08</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Joder, Cyril and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Temporal Integration for Audio Classification with Application to
  	Musical Instrument Classification}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Audio, Speech and Language Processing}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2009}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{17}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{174-186}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=article state=published doi=10.1109/TASL.2008.2007613 project=audiosig
  	dept=tsi group=aao documentURL=http://www.tsi.enst.fr/publications/enst/article-2009-8585.pdf
  	id=8585}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{:./papers/CJ_TASLP-09.pdf:PDF}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://www.tsi.enst.fr/publications/enst/article-2009-8585.pdf}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="MaxL:ICASSP09" class="col-sm-8"> <div class="title">INCORPORATING PRIOR KNOWLEDGE ON THE DIGITAL MEDIA CREATION PROCESS INTO AUDIO CLASSIFIERS</div> <div class="author"> M. Lardeur , <em>S. Essid</em>, G. Richard , M. Haller , and T. Sikora </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> , Apr 2009 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/ML_ICASSP-09.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">MaxL:ICASSP09</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lardeur, M. and Essid, Slim and Richard, Gael and Haller, M. and Sikora, T.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Incorporating prior knowledge on the digital media creation process
  	into audio classifiers}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Acoustics, Speech and Signal Processing
  	(ICASSP)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2009}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Taipei, Taiwan}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=published project=audiosig dept=tsi
  	group=aao id=9336}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{MaxL_ICASSP09.pdf:./papers/ML_ICASSP-09.pdf:PDF}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="AO:TREP-09" class="col-sm-8"> <div class="title">RECONNAISSANCE DES INSTRUMENTS DANS LA MUSIQUE POLYPHONIQUE PAR D&amp;EACUTE;COMPOSITION NMF ET CLASSIFICATION SVM</div> <div class="author"> A. Ozerov , <em>S. Essid</em>, and M. Charbit </div> <div class="periodical"> Apr 2009 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/AO_TREP-09.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@techreport</span><span class="p">{</span><span class="nl">AO:TREP-09</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ozerov, Alexey and Essid, Slim and Charbit, M.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Reconnaissance des instruments dans la musique polyphonique par d\&amp;eacute;composition
  	NMF et classification SVM}</span><span class="p">,</span>
  <span class="na">institution</span> <span class="p">=</span> <span class="s">{TELECOM ParisTech}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2009}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2009D014}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{AO_TREP-09.pdf:./papers/AO_TREP-09.pdf:PDF}</span><span class="p">,</span>
  <span class="na">owner</span> <span class="p">=</span> <span class="s">{essid}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{2009.08.11}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2008</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:ICIP-08" class="col-sm-8"> <div class="title">A COLLABORATIVE APPROACH TO AUTOMATIC RUSHES VIDEO SUMMARIZATION</div> <div class="author"> W. Bailer , E. Dumont , <em>S. Essid</em>, and B. Mérialdo </div> <div class="periodical"> <em>In IEEE ICIP Workshop on Multimedia Information Retrieval: New Trends and Challenges</em> , Oct 2008 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SE_ICIP-08.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SE:ICIP-08</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bailer, W. and Dumont, E. and Essid, Slim and M\&amp;eacute;rialdo, B.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Collaborative Approach to Automatic Rushes Video Summarization}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE ICIP Workshop on Multimedia Information Retrieval: New Trends
  	and Challenges}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2008}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=published project=audiosig dept=tsi
  	group=aao id=8679}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{SE_ICIP-08.pdf:./papers/SE_ICIP-08.pdf:PDF}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:SAMT-08" class="col-sm-8"> <div class="title">A COLLABORATIVE APPROACH TO VIDEO SUMMARIZATION</div> <div class="author"> E. Dumont , B. Merialdo , <em>S. Essid</em>, W. Bailer , D. Byrne , H. Bredin , N. OConnor , G. Jones , M. Haller , A. Krutz , T. Sikora , and T. Piatrik </div> <div class="periodical"> <em>In 3rd International Conference on Semantic and Digital Media Technologies (SAMT)</em> , Dec 2008 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SE_SAMT-08.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SE:SAMT-08</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dumont, E. and Merialdo, B. and Essid, Slim and Bailer, W. and Byrne, D. and Bredin, H. and OConnor, N. E. and Jones, G. J. F. and Haller, M. and Krutz, A. and Sikora, T. and Piatrik, T.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A collaborative approach to video summarization}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{3rd International Conference on Semantic and Digital Media Technologies
  	(SAMT)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2008}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Koblenz, Germany}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=published project=audiosig dept=tsi
  	group=aao id=8680}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{SE_SAMT-08.pdf:./papers/SE_SAMT-08.pdf:PDF}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:TRECVID-08" class="col-sm-8"> <div class="title">RUSHES VIDEO SUMMARIZATION USING A COLLABORATIVE APPROACH</div> <div class="author"> E. Dumont , B. Merialdo , <em>S. Essid</em>, W. Bailer , H. Rehatschek , D. Byrne , H. Bredin , N. OConnor , G. Jones , A. Smeaton , . M. Haller , A. Krutz , T. Sikora , and T. Piatrik </div> <div class="periodical"> <em>In TRECVID 2008, ACM International Conference on Multimedia Information Retrieval 2008</em> , Nov 2008 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SE_ACM-08.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SE:TRECVID-08</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dumont, E. and Merialdo, B. and Essid, Slim and Bailer, W. and Rehatschek, H. and Byrne, D. and Bredin, H. and OConnor, N. E. and Jones, G. J. F. and Smeaton, A. F. and and M. Haller and Krutz, A. and Sikora, T. and Piatrik, T.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Rushes video summarization using a collaborative approach}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{TRECVID 2008, ACM International Conference on Multimedia Information
  	Retrieval 2008}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2008}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Vancouver, BC, Canada}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=published project=audiosig dept=tsi
  	group=aao id=8681}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{SE_TRECVID-08.pdf:./papers/SE_ACM-08.pdf:PDF}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="CJ-EUSIPCO-2008" class="col-sm-8"> <div class="title">ALIGNMENT KERNELS FOR AUDIO CLASSIFICATION WITH APPLICATION TO MUSIC INSTRUMENT RECOGNITION</div> <div class="author"> C. Joder , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>In European Signal Processing Conference (EUSIPCO)</em> , Aug 2008 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/CJ_EUSIPCO-08.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">CJ-EUSIPCO-2008</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Joder, Cyril and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Alignment Kernels for Audio Classification with Application to Music
  	Instrument Recognition}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{European Signal Processing Conference (EUSIPCO)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2008}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Lausanne, Suisse}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=published project=audiosig dept=tsi
  	group=aao documentURL=http://www.tsi.enst.fr/publications/enst/inproceedings-2008-8528.pdf
  	id=8528}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{:./papers/CJ_EUSIPCO-08.pdf:PDF}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://www.tsi.enst.fr/publications/enst/inproceedings-2008-8528.pdf}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SW:EUSIPCO08" class="col-sm-8"> <div class="title">ON THE ROBUSTNESS OF AUDIO FEATURES FOR MUSICAL INSTRUMENT CLASSIFICATION</div> <div class="author"> S. Wegener , M. Haller , J. Burred , T. Sikora , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>In European Signal Processing Conference (EUSIPCO)</em> , Sep 2008 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SW_EUSIPCO08.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SW:EUSIPCO08</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wegener, S. and Haller, M. and Burred, J.-J. and Sikora, T. and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{On the Robustness of Audio Features for Musical Instrument Classification}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{European Signal Processing Conference (EUSIPCO)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2008}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Lausanne, Switzerland}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=published project=audiosig dept=tsi
  	group=aao id=8616}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{SW_EUSIPCO08.pdf:./papers/SW_EUSIPCO08.pdf:PDF}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2007</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="OG:CVST-07" class="col-sm-8"> <div class="title">ON THE CORRELATION OF AUTOMATIC AUDIO AND VISUAL SEGMENTATIONS OF MUSIC VIDEOS</div> <div class="author"> O. Gillet , <em>S. Essid</em>, and G. Richard </div> <div class="periodical"> <em>IEEE Transactions on Circuits and Systems for Video Technology</em>, Mar 2007 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/OG_TCSVT-07.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">OG:CVST-07</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Gillet, O. and Essid, Slim and Richard, Gael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{On the Correlation of Automatic Audio and Visual Segmentations of
  	Music Videos}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Circuits and Systems for Video Technology}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2007}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=article state=published project=audiosig dept=tsi group=aao
  	id=6864}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{OG_CVST-07.pdf:./papers/OG_TCSVT-07.pdf:PDF}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="ICA:07" class="col-sm-8"> <div class="title">TOWARDS POLYPHONIC MUSICAL INSTRUMENT RECOGNITION</div> <div class="author"> G. Richard , P. Leveau , L. Daudet , <em>S. Essid</em>, and B. David </div> <div class="periodical"> <em>In International Congress on Acoustics (ICA)</em> , Sep 2007 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/GR_ICA-07.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ICA:07</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Richard, Gael and Leveau, P. and Daudet, L. and Essid, Slim and David, Bertrand}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Towards polyphonic musical instrument recognition}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Congress on Acoustics (ICA)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2007}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Madrid}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=published project=audiosig dept=tsi
  	group=aao id=7332}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{ICA_07.pdf:./papers/GR_ICA-07.pdf:PDF}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="GR:Icassp-07" class="col-sm-8"> <div class="title">COMBINED SUPERVISED AND UNSUPERVISED APPROACHES FOR AUTOMATIC SEGMENTATION OF RADIOPHONIC AUDIO STREAMS</div> <div class="author"> G. Richard , M. Ramona , and <em>S. Essid</em> </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> , Apr 2007 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/GR_ICASSP-07.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">GR:Icassp-07</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Richard, Gael and Ramona, M. and Essid, Slim}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Combined supervised and unsupervised approaches for automatic segmentation
  	of radiophonic audio streams}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Acoustics, Speech and Signal Processing
  	(ICASSP)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2007}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Honolulu, Hawai}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=published project=audiosig dept=tsi
  	group=aao id=6862}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{GR_Icassp-07.pdf:./papers/GR_ICASSP-07.pdf:PDF}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:TRECVID-07" class="col-sm-8"> <div class="title">K-SPACE AT TRECVID 2007</div> <div class="author"> P. Wilkins , T. Adamek , D. Byrne , G. Jones , H. Lee , G. Keenan , K. Guinness , N. OConnor , A. Smeaton , A. Amin , Z. Obrenovic , R. Benmokhtar , E. Galmar , B. Huet , <em>S. Essid</em>, R. Landais , F. Vallet , G. Papadopoulos , S. Vrochidis , V. Mezaris , I. Kompatsiaris , E. Spyrou , Y. Avrithis , R. Morzinger , P. Schallauer , W. Bailer , T. Piatrik , K. Chandramouli , E. Izquierdo , M. Haller , L. Goldmann , A. Samour , A. Cobet , T. Sikora , and P. Praks </div> <div class="periodical"> <em>In TRECVID 2007</em> , Nov 2007 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SE_TRECVID-07.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SE:TRECVID-07</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wilkins, P. and Adamek, T. and Byrne, D. and Jones, G. J. F. and Lee, H. and Keenan, G. and Guinness, K. Mc and OConnor, N. E. and Smeaton, A. F. and Amin, A. and Obrenovic, Z. and Benmokhtar, R. and Galmar, E. and Huet, B. and Essid, Slim and Landais, R. and Vallet, F. and Papadopoulos, G. T. and Vrochidis, S. and Mezaris, V. and Kompatsiaris, I. and Spyrou, E. and Avrithis, Y. and Morzinger, R. and Schallauer, P. and Bailer, W. and Piatrik, T. and Chandramouli, K. and Izquierdo, E. and Haller, M. and Goldmann, L. and Samour, A. and Cobet, A. and Sikora, T. and Praks, P.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{K-Space at TRECVid 2007}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{TRECVID 2007}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2007}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=published project=audiosig dept=tsi
  	group=aao documentURL=http://www.cdvp.dcu.ie/Papers/kspace-tv2007.pdf
  	id=7755}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{:./papers/SE_TRECVID-07.pdf:PDF}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://www.cdvp.dcu.ie/Papers/kspace-tv2007.pdf}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2006</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:COD-06" class="col-sm-8"> <div class="title">INSTRUMENT RECOGNITION IN POLYPHONIC MUSIC BASED ON AUTOMATIC TAXONOMIES</div> <div class="author"> <em>S. Essid</em>, G. Richard , and B. David </div> <div class="periodical"> <em>IEEE Transactions on Audio, Speech, and Language Processing</em>, Jan 2006 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SE_TSALP-06b.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">SE:COD-06</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Essid, Slim and Richard, Gael and David, Bertrand}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Instrument recognition in polyphonic music based on automatic taxonomies}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Audio, Speech, and Language Processing}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2006}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{14}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{68-80}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=article state=published doi=10.1109/TSA.2005.860351 project=audiosig
  	dept=tsi group=aao id=5909}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{SE_COD-06.pdf:./papers/SE_TSALP-06b.pdf:PDF}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:COD-06-2" class="col-sm-8"> <div class="title">MUSICAL INSTRUMENT RECOGNITION BY PAIRWISE CLASSIFICATION STRATEGIES</div> <div class="author"> <em>S. Essid</em>, G. Richard , and B. David </div> <div class="periodical"> <em>IEEE Transactions on Audio, Speech, and Language Processing</em>, Jul 2006 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SE_TSALP-06a.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">SE:COD-06-2</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Essid, Slim and Richard, Gael and David, Bertrand}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Musical instrument recognition by pairwise classification strategies}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Audio, Speech, and Language Processing}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2006}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{14}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1401- 1412}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=article state=published doi=10.1109/TSA.2005.860842 project=audiosig
  	dept=tsi group=aao id=5910}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{SE_COD-06-2.pdf:./papers/SE_TSALP-06a.pdf:PDF}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:ICASSP-06" class="col-sm-8"> <div class="title">HIERARCHICAL CLASSIFICATION OF MUSICAL INSTRUMENTS ON SOLO RECORDINGS</div> <div class="author"> <em>S. Essid</em>, G. Richard , and B. David </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> , May 2006 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SE_ICASSP-06.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SE:ICASSP-06</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Essid, Slim and Richard, Gael and David, Bertrand}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hierarchical Classification of Musical Instruments on Solo Recordings}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Acoustics, Speech and Signal Processing
  	(ICASSP)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2006}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Toulouse, France}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=published project=audiosig dept=tsi
  	group=aao id=6672}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{SE_ICASSP-06.pdf:./papers/SE_ICASSP-06.pdf:PDF}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2005</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:these" class="col-sm-8"> <div class="title">CLASSIFICATION AUTOMATIQUE DES SIGNAUX AUDIO-FR&amp;EACUTE;QUENCES: RECONNAISSANCE DES INSTRUMENTS DE MUSIQUE</div> <div class="author"> <em>S. Essid</em> </div> <div class="periodical"> <em>Université Pierre et Marie Curie</em> , Dec 2005 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SE_PhD-05.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@phdthesis</span><span class="p">{</span><span class="nl">SE:these</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Essid, Slim}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Classification automatique des signaux audio-fr\&amp;eacute;quences:
  	reconnaissance des instruments de musique}</span><span class="p">,</span>
  <span class="na">school</span> <span class="p">=</span> <span class="s">{Universit\&amp;eacute; Pierre et Marie Curie}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2005}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=phdthesis state=published project=audiosig dept=tsi group=aao
  	id=7638}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{SE_these.pdf:./papers/SE_PhD-05.pdf:PDF}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE-ICASSP-05" class="col-sm-8"> <div class="title">INSTRUMENT RECOGNITION IN POLYPHONIC MUSIC</div> <div class="author"> <em>S. Essid</em>, G. Richard , and B. David </div> <div class="periodical"> <em>In IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> , Mar 2005 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SE_ICASSP-05.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SE-ICASSP-05</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Essid, Slim and Richard, Gael and David, Bertrand}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Instrument recognition in polyphonic music}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Acoustics, Speech and Signal Processing
  	(ICASSP)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2005}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Philadelphia, US}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=published project=audiosig dept=tsi
  	group=aao id=5067}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{SE-ICASSP-05.pdf:./papers/SE_ICASSP-05.pdf:PDF}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="PL-AES-05" class="col-sm-8"> <div class="title">ON THE USEFULNESS OF DIFFERENTIATED TRANSIENT/STEADY-STATE PROCESSING IN MACHINE RECOGNITION OF MUSICAL INSTRUMENTS</div> <div class="author"> P. Leveau , <em>S. Essid</em>, G. Richard , L. Daudet , and B. David </div> <div class="periodical"> <em>In AES convention</em> , May 2005 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SE_AES-05.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">PL-AES-05</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Leveau, P. and Essid, Slim and Richard, Gael and Daudet, L. and David, Bertrand}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{On the usefulness of differentiated transient/steady-state processing
  	in machine recognition of musical instruments}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{AES convention}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2005}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Barcelona, Spain}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=published project=audiosig dept=tsi
  	group=aao id=5071}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{PL-AES-05.pdf:./papers/SE_AES-05.pdf:PDF}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2004</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:AES-04" class="col-sm-8"> <div class="title">EFFICIENT MUSICAL INSTRUMENT RECOGNITION ON SOLO PERFORMANCES USING BASIC FEATURES</div> <div class="author"> <em>S. Essid</em>, G. Richard , and B. David </div> <div class="periodical"> <em>In AES 25th conference</em> , Jun 2004 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SE_AES-04.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SE:AES-04</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Essid, Slim and Richard, Gael and David, Bertrand}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Efficient musical instrument recognition on solo performances using
  	basic features}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{AES 25th conference}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2004}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{London, UK}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=published project=audiosig dept=tsi
  	group=aao,cod id=3608}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{SE_AES-04.pdf:./papers/SE_AES-04.pdf:PDF}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:Eusipco-04" class="col-sm-8"> <div class="title">MUSICAL INSTRUMENT RECOGNITION ON SOLO PERFORMANCES</div> <div class="author"> <em>S. Essid</em>, G. Richard , and B. David </div> <div class="periodical"> <em>In European Signal Processing Conference (EUSIPCO)</em> , Sep 2004 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SE_AES-04.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SE:Eusipco-04</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Essid, Slim and Richard, Gael and David, Bertrand}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Musical instrument recognition on solo performances}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{European Signal Processing Conference (EUSIPCO)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2004}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Vienna, Austria}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=published project=audiosig dept=tsi
  	group=aao,cod documentURL=http://www.enst.fr/~grichard/publications.htm
  	id=4893}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{:D\:\\documents\\myPage\\papers\\SE_EUSIPCO-04.pdf:PDF}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://www.enst.fr/~grichard/publications.htm}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:ISMIR-04" class="col-sm-8"> <div class="title">MUSICAL INSTRUMENT RECOGNITION BASED ON CLASS PAIRWISE FEATURE SELECTION</div> <div class="author"> <em>S. Essid</em>, G. Richard , and B. David </div> <div class="periodical"> <em>In International Conference on Music Information Retrieval (ISMIR)</em> , Oct 2004 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SE_ISMIR-04.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SE:ISMIR-04</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Essid, Slim and Richard, Gael and David, Bertrand}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Musical instrument recognition based on class pairwise feature selection}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Music Information Retrieval (ISMIR)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2004}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Barcelona, Spain}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=published project=audiosig dept=tsi
  	group=aao,cod documentURL=http://www.enst.fr/~grichard/publications.htm
  	id=4892}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{:./papers/SE_ISMIR-04.pdf:PDF}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://www.enst.fr/~grichard/publications.htm}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2003</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:GRETSI-03" class="col-sm-8"> <div class="title">MOD&amp;EGRAVE;LES SINUSO&amp;IUML;DAUX &amp;EACUTE;TENDUS POUR LE CODAGE AUDIO</div> <div class="author"> R. Boyer , <em>S. Essid</em>, K. Abed-Meraim , and N. Moreau </div> <div class="periodical"> <em>In Dix-neuvième colloque sur le Traitement du Signal et des Images</em> , Sep 2003 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/RB_GRETSI-03.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SE:GRETSI-03</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Boyer, R. and Essid, Slim and Abed-Meraim, K. and Moreau, N.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Mod\&amp;egrave;les sinuso\&amp;iuml;daux \&amp;eacute;tendus pour le codage
  	audio}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Dix-neuvi\&amp;egrave;me colloque sur le Traitement du Signal et des
  	Images}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2003}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Paris, France}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=published project= dept=tsi group=aao,cod,tsac
  	id=3453}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{SE_GRETSI-03.pdf:./papers/RB_GRETSI-03.pdf:PDF}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2002</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="RB:DSP-02" class="col-sm-8"> <div class="title">TRANSIENT MODELING WITH A FREQUENCY-TRANSFORM SUBSPACE ALGORITHM AND TRANSIENT + SINUSOIDAL SCHEME</div> <div class="author"> R. Boyer , and <em>S. Essid</em> </div> <div class="periodical"> <em>In 14th IEEE Int. Conf. on Digital Signal Proc.</em> , Jul 2002 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/RB_DSP-02.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>We present an efficient modeling method for strong transient character audio signals. It is shown that the parametric non-stationary exponentially damped sinusoids (EDS) model permits good performance for time domain modeling of quasi-stationary signals or "weak" transients. However, a decay in modeling performance is observed when dealing with highly nonstationary signals as in a variety of musical sounds (various percussions, castanets, triangle,...). The idea is then to process the signal in a well chosen frequency-transform domain in which the transient temporal characteristics are better modeled by EDS. As a result, better representations of the transient signal class are obtained with no pre-echo artifacts (energy before the attack) and a very good signal onset dynamic reproduction. Finally, an original "transient+sinusoidal" modeling scheme is proposed.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">RB:DSP-02</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Boyer, R. and Essid, Slim}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Transient modeling with a Frequency-Transform Subspace Algorithm
  	and Transient + Sinusoidal scheme}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{14th IEEE Int. Conf. on Digital Signal Proc.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2002}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Santorini (Greece)}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=published project= dept=tsi group=cod
  	id=2014}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{RB_DSP-02.pdf:./papers/RB_DSP-02.pdf:PDF}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="RB:ICM-02" class="col-sm-8"> <div class="title">DYNAMIC TEMPORAL SEGMENTATION IN PARAMETRIC NON-STATIONARY MODELING FOR PERCUSSIVE MUSICAL SIGNALS</div> <div class="author"> R. Boyer , <em>S. Essid</em>, and N. Moreau </div> <div class="periodical"> <em>In IEEE Int. Conf. on Multimedia and Expo (ICME)</em> , Aug 2002 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/RB_ICM-02.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>An audio signal parametric modeling scheme is proposed that permits higher performance for representing strong sound transients. The exponentially damped sinusoids (EDS) model is considered in association with a high resolution parameter estimation approach. Such a technique is well adapted to almost every audio signal but is unfortunately not efficient when dealing with signals presenting strong temporal variations, such as percussive music signals, and causes pre-echo artifacts and weak onset dynamic reproduction which are prejudicial to listening. A system, based on the EDS model, has been developed with a transient detector and dynamic time segmentation and modeling that allows to overcome such artifacts.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">RB:ICM-02</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Boyer, R. and Essid, Slim and Moreau, N.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Dynamic temporal segmentation in parametric non-stationary modeling
  	for percussive musical signals}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE Int. Conf. on Multimedia and Expo (ICME)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2002}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Lausanne, Switzerland}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=published project= dept=tsi group=cod
  	id=2013}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{RB_ICM-02.pdf:./papers/RB_ICM-02.pdf:PDF}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="RB:ICS-02" class="col-sm-8"> <div class="title">NON-STATIONARY SIGNAL PARAMETRIC MODELING TECHNIQUES WITH AN APPLICATION TO LOW BITRATE AUDIO CODING</div> <div class="author"> R. Boyer , <em>S. Essid</em>, and N. Moreau </div> <div class="periodical"> <em>In 6th IEEE Int. Conf. Signal Processing</em> , Aug 2002 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/RB_ICS-02.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Low bit rate audio coding often relies on Fourier representation despite its limitations for transient signal modeling. This study proposes alternative decompositions and expansion strategies that lead to more accurate modeling. Two classes of methods are considered, subspace decomposition methods, and atomic decomposition methods and their performances are compiled to propose an audio modeling scheme amenable to low bit rate coding.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">RB:ICS-02</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Boyer, R. and Essid, Slim and Moreau, N.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Non-stationary signal parametric modeling techniques with an application
  	to low bitrate audio coding}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{6th IEEE Int. Conf. Signal Processing}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2002}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Beijing, China}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=published project= dept=tsi group=cod
  	id=2012}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{RB_ICS-02.pdf:./papers/RB_ICS-02.pdf:PDF}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="SE:master-02" class="col-sm-8"> <div class="title">CODEUR AUDIO PARAM&amp;EACUTE;TRIQUE BAS D&amp;EACUTE;BIT BAS&amp;EACUTE; SUR UN MOD&amp;EGRAVE;LE "SINUSO&amp;IUML;DES AMORTIES EXPONENTIELLEMENT + TRANSITOIRES + BRUIT"</div> <div class="author"> <em>S. Essid</em> </div> <div class="periodical"> <em>Ecole Nationale Supérieure des Télécommunications (ENST)</em> , Oct 2002 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/SE_MastTh-02.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@mastersthesis</span><span class="p">{</span><span class="nl">SE:master-02</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Essid, Slim}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Codeur audio param\&amp;eacute;trique bas d\&amp;eacute;bit bas\&amp;eacute;
  	sur un mod\&amp;egrave;le "Sinuso\&amp;iuml;des Amorties Exponentiellement
  	+ Transitoires + Bruit"}</span><span class="p">,</span>
  <span class="na">school</span> <span class="p">=</span> <span class="s">{Ecole Nationale Sup\&amp;eacute;rieure des T\&amp;eacute;l\&amp;eacute;communications
  	(ENST)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2002}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{dea.pdf:./papers/SE_MastTh-02.pdf:PDF}</span><span class="p">,</span>
  <span class="na">owner</span> <span class="p">=</span> <span class="s">{essid}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{2009.08.11}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2001</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Boyer_01" class="col-sm-8"> <div class="title">EXPLORATION DE TECHNIQUES MODERNES DE MOD&amp;EACUTE;LISATION ADAPT&amp;EACUTE;ES &amp;AGRAVE; DU CODAGE AUDIO BAS-D&amp;EACUTE;BIT</div> <div class="author"> R. Boyer , <em>S. Essid</em>, and N. Moreau </div> <div class="periodical"> <em>In 7èmes Journées d Etudes et d Echanges : Compression et Représentation des Signaux Audiovisuels (CORESA)</em> , Oct 2001 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/research/assets/pdf/papers/RB_CORESA-01.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Boyer_01</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Boyer, R. and Essid, Slim and Moreau, N.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Exploration de techniques modernes de mod\&amp;eacute;lisation adapt\&amp;eacute;es
  	\&amp;agrave; du codage audio bas-d\&amp;eacute;bit}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{7\&amp;egrave;mes Journ\&amp;eacute;es d Etudes et d Echanges : Compression
  	et Repr\&amp;eacute;sentation des Signaux Audiovisuels (CORESA)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2001}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Dijon, France}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{category=inproceedings state=published project= dept=tsi group=cod
  	id=1971}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{RB_CORESA-01.pdf:./papers/RB_CORESA-01.pdf:PDF}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Slim Essid. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Last updated: March 06, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/research/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/research/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/research/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/research/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/research/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script> <script defer src="/research/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>